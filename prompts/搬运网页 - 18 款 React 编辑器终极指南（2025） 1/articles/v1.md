---
title: "AI Agent 架构深度指南：为何强大≠好用？"
subtitle: "一篇为PM和创业者准备的Agent架构、协同模式与信任策略完全指南，揭示为何高能力Agent依然遭遇用户流失的真相。"
date: 2025-09-05
source: https://www.productcurious.com/p/a-pms-guide-to-ai-agent-architecture
---

上周，我与一位最近刚发布了自家 AI Agent 的产品经理交流。数据看起来相当亮眼：89% 的准确率、亚秒级的响应时间、用户调研反馈积极。然而，用户在遇到第一个稍微复杂点的问题后，就迅速放弃了它。比如，一个用户同时遇到了账单争议和账户锁定的双重麻烦。

> “我们的 Agent 能完美处理常规请求，但一旦面临复杂问题，用户尝试一次受挫后，就会立刻要求转接人工。”

这种模式在几乎所有只关注让 Agent “更智能”的产品团队中都普遍存在。但真正的挑战在于，**架构层面的决策，才最终塑造了用户体验和信任建立的方式。**

在这篇文章中，我将带你深入剖析 AI Agent 架构的各个层面，探讨你的产品决策如何决定用户是信任你的 Agent，还是最终抛弃它。读完本文，你将理解为何有些 Agent 让人感觉“充满魔力”，而另一些则让人“倍感挫败”，更重要的是，产品经理应如何从架构层面设计出那种“魔力般的体验”。

我们将始终围绕一个具体的客户支持 Agent 案例，让你直观地看到每个架构选择在实践中如何发挥作用。我们还将探讨一个反直觉的信任建立方法（提示：关键不在于更频繁地做对），以及它为何对用户采纳更有效。

## 案例：构建一个客户支持 Agent

假设你是一名产品经理，正在构建一个帮助用户处理账户问题的 Agent——重置密码、账单疑问、套餐变更。听起来很简单，对吧？

![ConversationRelay | Twilio](https://substackcdn.com/image/fetch/$s_!lsF4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4bee9fce-5586-4d0c-a98b-d54f816e1a85_1128x786.webp "ConversationRelay | Twilio")

但是，当用户说出 **“我无法访问我的账户，而且我的订阅看起来有问题”** 时，应该发生什么？

**场景 A：** 你的 Agent 立即开始检查系统。它查询账户，识别出密码昨天被重置但邮件从未送达，同时发现一个账单问题导致了套餐降级。然后，它精准地解释了事情的来龙去脉，并提供一键修复这两个问题的选项。

**场景 B：** 你的 Agent 开始提出澄清性问题。“您最后一次成功登录是什么时候？您看到了什么错误信息？能详细描述一下订阅问题吗？” 在收集信息后，它说：“让我为您转接人工客服，他们可以检查您的账户和账单。”

<!-- 评注建议：这里可以从产品哲学的角度切入，对比“全能型代理”和“协作型助手”两种不同的产品定位。并引出这对后续架构选型、用户预期管理至关重要的观点。 -->

同样的用户请求，同样的底层系统，却诞生了**完全不同的产品**。

## 你的产品决策，存在于这四个架构层

将 Agent 架构想象成一个技术栈，每一层都代表一个你必须做出的产品决策。

![](https://substackcdn.com/image/fetch/$s_!JMHA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6d1c3e46-44f3-4986-b1b1-b50c7e9ffb4e_804x904.png)

### 第一层：上下文与记忆 (Context & Memory)

**决策点：** 你的 Agent 应该记住多少信息？记忆应该持续多久？

这不仅仅是技术存储问题，它关乎**创造一种“理解”的幻觉**。Agent 的记忆决定了用户感觉是在与一个机器人对话，还是在与一位知识渊博的同事沟通。

**对于我们的支持 Agent：** 你是只存储当前对话，还是客户的全部支持历史？他们的产品使用模式？过去的投诉记录？

**需要考虑的记忆类型：**

- **会话记忆 (Session memory):** 当前对话（“您之前提到了账单问题……”）
- **客户记忆 (Customer memory):** 跨会话的历史交互（“上个月您也遇到了一个类似的问题……”）
- **行为记忆 (Behavioral memory):** 使用模式（“我注意到您通常使用我们的移动应用……”）
- **情境记忆 (Contextual memory):** 当前账户状态、有效订阅、近期活动

Agent 记得越多，就越能预测需求，而不仅仅是响应问题。每一层记忆都让响应更智能，但也增加了复杂性和成本。

### 第二层：数据与集成 (Data & Integration)

**决策点：** 你的 Agent 应该连接哪些系统？应该赋予它多大级别的访问权限？

Agent 与用户工作流和现有系统的连接越深，用户的转换成本就越高。这一层决定了你是在做一个**工具**，还是一个**平台**。

**对于我们的支持 Agent：** 它应该只集成 Stripe 的账单系统，还是同时集成 Salesforce CRM、ZenDesk 工单系统、用户数据库和审计日志？每个集成都使 Agent 更有用，但同时也创造了更多的潜在故障点——想想 API 速率限制、认证挑战和系统停机时间。

有趣的是，大多数团队都试图一次性集成所有东西，但最成功的 Agent 往往从 2-3 个关键集成开始，然后根据用户的实际需求逐步增加。

### 第三层：技能与能力 (Skills & Capabilities)

**决策点：** 你的 Agent 应该具备哪些具体能力？这些能力的深度如何？

技能层是你与竞争对手一决胜负的地方。关键不在于拥有最多的功能，而在于拥有**能创造用户依赖的正确能力**。

**对于我们的支持 Agent：** 它应该只能读取账户信息，还是应该也能修改账单、重置密码和更改套餐设置？每增加一项技能都会提升用户价值，但同样会增加复杂性和风险。

![How to Use Model Context Protocol for Scalable AI Integrations?](https://substackcdn.com/image/fetch/$s_!AfC4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6ace5e82-816b-426e-abc7-b9c8733a14d5_1146x931.png "How to Use Model Context Protocol for Scalable AI Integrations?")

**实现注意：** 像 [MCP (Model Context Protocol)](https://www.productcurious.com/p/the-new-distribution-game-building) 这样的工具，正在让跨不同 Agent 构建和共享技能变得更加容易，而无需从头重建能力。

<!-- 评注建议：这是一个极佳的框架。可以补充评论，强调这“四层决策”本质上是产品经理在AI时代的核心能力图谱，是从“功能规格”思维转向“系统架构”思维的体现。 -->

### 第四层：评估与信任 (Evaluation & Trust)

**决策点：** 你如何衡量成功，并向用户传达 Agent 的局限性？

这一层决定了用户是会对你的 Agent 建立信心，还是在第一次失误后就弃之不用。这不仅仅是关于**准确**，更是关于**值得信赖**。

**对于我们的支持 Agent：** 你会显示置信度分数吗（“我有 85% 的把握这能解决你的问题”）？你会解释你的推理过程吗（“我检查了三个系统，发现……”）？你会在采取行动前总是进行确认吗（“我现在应该重置您的密码吗？”）？每个选择都会影响用户对可靠性的感知。

**值得考虑的信任策略：**

- **置信度指标 (Confidence indicators):** “我对您的账户状态很有信心，但请让我再次核对一下账单细节。”
- **推理透明度 (Reasoning transparency):** “我发现了两次失败的登录尝试和一个过期的支付方式。”
- **优雅的边界 (Graceful boundaries):** “这看起来是一个复杂的账单问题——让我为您连接我们的账单专家，他们有权限使用更多工具。”
- **确认模式 (Confirmation patterns):** 何时应该请求许可，何时应该先行动再解释。

> 反直觉的洞见：**当 Agent 承认不确定性时，用户反而更信任它，而不是当它自信地犯错时。**

---

## 那么，到底该如何架构一个 Agent？

好了，你已经理解了这些层次。现在，每个 PM 都会问一个实际问题：“我究竟该如何实现它？Agent 如何与技能对话？技能如何访问数据？在用户等待时，评估又是如何进行的？”

**你的协同（Orchestration）模式选择，决定了你的开发体验、调试流程以及快速迭代的能力。**

![](https://substackcdn.com/image/fetch/$s_!B42p!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7ad3a5c4-6a5b-4553-9b3e-0567b150f3da_1610x766.png)

让我们来看看几种主流方法，以及它们各自的优缺点。

### 1. 单体 Agent 架构 (Single-Agent Architecture)

**从这里开始。** 所有事情都在一个 Agent 的上下文中发生。

**对于我们的支持 Agent：** 当用户说“我无法访问我的账户”时，一个 Agent 处理所有事情——检查账户状态、识别账单问题、解释发生了什么、提供解决方案。

**优点：** 构建简单，易于调试，成本可预测。你清楚地知道你的 Agent 能做什么和不能做什么。
**缺点：** 处理复杂请求时可能会变得昂贵，因为每次都需要加载完整的上下文。难以对特定部分进行优化。

> 大多数团队都从这里开始，坦白说，很多团队也根本不需要超越这个阶段。如果你在它和更复杂的架构之间犹豫，**请从这里开始**。

### 2. 基于技能的架构 (Skill-Based Architecture)

**当你需要效率时。** 你有一个“路由器”来判断用户需要什么，然后将任务分派给专门的技能。

**对于我们的支持 Agent：** 路由器意识到这是一个账户访问问题，并将其路由到 `LoginSkill`。如果 `LoginSkill` 发现这其实是一个账单问题，它会把任务移交给 `BillingSkill`。

**真实流程示例：**

1.  *用户: "我登不进去"*
2.  *路由器 → LoginSkill*
3.  *LoginSkill 检查: 账户存在 ✓, 密码正确 ✗, 账单状态... 等等，订阅已过期*
4.  *LoginSkill → BillingSkill: "为 user123 处理订阅过期问题"*
5.  *BillingSkill 处理续订流程*

**优点：** 更高效。你可以为简单的技能使用更便宜的模型，为复杂的推理使用昂贵的模型。每个技能都可以独立优化。
**缺点：** 技能之间的协调很快会变得棘手。谁来决定何时移交？技能如何共享上下文？

> 这正是 MCP 大显身手的地方——它标准化了技能暴露其能力的方式，因此你的路由器无需手动维护映射关系，就能知道每个技能能做什么。

### 3. 基于工作流的架构 (Workflow-Based Architecture)

**企业级最爱。** 你为常见场景预先定义了逐步的流程。可以想象成 LangGraph, CrewAI, AutoGen, N8N 等工具。

**对于我们的支持 Agent：** “账户访问问题”会触发一个工作流：

1.  *检查账户状态*
2.  *如果被锁定，检查失败的登录尝试*
3.  *如果失败次数过多，检查账单状态*
4.  *如果是账单问题，路由到支付恢复流程*
5.  *如果不是账单问题，路由到密码重置流程*

**优点：** 一切都可预测且可审计。非常适合合规性要求高的行业。易于优化每个步骤。
**缺点：** 当用户遇到不符合你预定义工作流的边缘案例时，系统就卡住了。对用户来说感觉很僵化。

### 4. 协作式架构 (Collaborative Architecture)

**未来？** 多个专业 Agent 使用 A2A (agent-to-agent) 协议协同工作。

**愿景：** 你的 Agent 发现另一家公司的 Agent 可以帮助解决问题，于是自动建立安全连接，并协作解决客户的问题。**想象一下 booking.com 的 Agent 与美国航空的 Agent 直接对话！**

**对于我们的支持 Agent：** `AuthenticationAgent` 处理登录问题，`BillingAgent` 处理支付问题，`CommunicationAgent` 管理用户交互。它们通过标准化协议进行协调，以解决复杂问题。

**现实检验：** 这听起来很棒，但引入了关于安全、计费、信任和可靠性的巨大复杂性，大多数公司还没准备好。我们仍在探索相关标准。

这种架构可以为复杂场景带来惊人的结果，但调试多 Agent 对话真的非常困难。当出现问题时，要找出是哪个 Agent 犯了错以及原因，就像侦探工作一样。

<!-- 评注建议：协作式架构是AGI的雏形，但作者点出了当下的困境。这里可以深入探讨，目前所谓的“多智能体协作”框架（如AutoGen, CrewAI）与真正的A2A协议还有多远距离，点出现阶段“编排”重于“涌现”的现实。 -->

![Overview](https://substackcdn.com/image/fetch/$s_!KdJQ!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9c4507e2-2478-4d44-aaee-82024692d318_1492x1226.png "Overview")

**关键在于：** **从简单开始**。单体 Agent 架构能处理的用例远比你想象的要多。只有当你遇到真正的、而非想象中的瓶颈时，才去增加复杂性。

但有趣的是，即使拥有完美的架构，如果用户不信任它，你的 Agent 仍然会失败。这引出了我们关于构建 Agent 的最反直觉的一课。

---

## 那个所有人都搞错了的信任问题

这是一个反直觉的观点：**用户不信任那些永远正确的 Agent。他们信任那些能坦诚承认自己可能出错的 Agent。**

从用户的角度思考一下。你的支持 Agent 自信地说：“我已经重置了您的密码并更新了您的账单地址。” 用户心想“太好了！” 然后他们尝试登录，却……失败了。现在他们不仅面临一个技术问题，更面临一个**信任问题**。

<!-- 评注建议：这是全文的点睛之笔。可以从心理学角度分析，用户信任的建立并非源于“不出错”，而是源于“可预测”和“可控制”。AI Agent主动示弱、暴露不确定性，本质上是将控制权和最终判断权交还给用户，从而建立信任。这是反直觉但至关重要的产品心法。 -->

与之对比，一个 Agent 这样说：“我想我找到了您账户的问题所在。我有 80% 的把握这能解决问题。我将为您重置密码并更新账单地址。如果这没有用，我会立即为您转接人工客服进行深入处理。”

**同样的技术能力，完全不同的用户体验。**

构建值得信赖的 Agent 需要关注三件事：

1.  **置信度校准 (Confidence calibration):** 当你的 Agent 说它有 60% 的把握时，它的正确率就应该是 60% 左右。不是 90%，也不是 30%。就是真实的 60%。

2.  **推理透明度 (Reasoning transparency):** 用户希望看到 Agent 的“工作过程”。“我检查了您的账户状态（活跃）、账单历史（昨天支付失败）和登录尝试（3次失败后锁定）。问题似乎是……”

3.  **优雅的升级 (Graceful escalation):** 当 Agent 达到其能力极限时，它如何交接？一个带着完整上下文平滑过渡到人工客服的体验，远比一句“我无法处理这个问题”要好得多。

很多时候，我们痴迷于让 Agent 更准确，而用户真正想要的，却是对 Agent 局限性更清晰的认知。

---

## 接下来会发生什么

在第二部分，作者将更深入地探讨让大多数 PM 夜不能寐的自主性决策。你应该给你的 Agent 多大的独立性？它应该何时请求许可，何时可以“先斩后奏”？你如何在自动化和用户控制之间取得平衡？

我们还将探讨在实践中真正重要的治理问题——不仅仅是理论上的安全问题，而是那些可能决定你产品发布成败的真实挑战。

如果你读完了这篇指南，请与你的朋友分享，并订阅原文！

<!-- 评注建议：在总结部分，可以拔高一层。将这篇文章的架构思考，与更宏大的“AI产品化”浪潮结合。指出未来PM的核心竞争力，将是如何设计好AI与人的“信任边界”和“协作接口”，而不仅仅是提升模型的单点能力。 -->