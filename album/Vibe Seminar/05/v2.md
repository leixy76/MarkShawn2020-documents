好的，作为“Vibe Genius”社区的内容主理人，我将基于提供的速记材料，整理并撰写一篇符合社区调性与专业水准的深度纪要。

# 【Vibe Genius #01】MBTI as Prompt: 当代码与灵魂相遇

> 当一群顶尖的开发者与 AI 从业者聚在一起，他们会聊些什么？出乎意料，这场长达三个半小时的闭门交流，竟是从一个略带“玄学”色彩的心理学工具——MBTI 开始的。这并非偶然，而是对 AI Agent 未来形态的一次深刻预判：如果 AI Agent 终将拥有“人格”，我们该如何与之沟通、协作，甚至“管理”？这场讨论从一个名为 `output styles` 的 `cloud code` 功能切入，逐步深入到 Prompt 系统工程、多 Agent 协作、人机交互的终极形态，以及 AI 原生时代的商业逻辑等一系列前沿议题。

### **Key Insights**

*   **MBTI as Prompt：一种新型人机对齐范式**
    我们不仅可以，而且应该为 AI Agent 设定精细的“人格”，如同 MBTI 的 16 种人格类型。这种人格化不仅是简单的角色扮演，而是通过一套包含行为模式、沟通偏好、决策风格的复杂指令集，在系统层面（System Prompt）实现与 AI 的深度对齐，从而在特定任务中获得远超通用 Prompt 的性能。

*   **“Prompt 漂洗”：用 AI 的逻辑重塑人类的表达**
    直接用自然语言撰写的复杂 Prompt 往往是“人类友好”但“机器模糊”的。一个高效的工作流是：先用一个强大的生成模型（如 KIMI）将一个概念（如某种 MBTI 人格）“发散”成数万字的详细描述，再利用另一个专门面向代码和逻辑的工具（如 `cloud code`）对其进行“漂洗”和“压缩”，将其转化为结构化、逻辑一致的“机器可读”指令集。

*   **`output styles`: 在系统层面“Hack”AI 的人格**
    `cloud code` 的 `output styles` 功能本质上是一种对 System Prompt 的“注入”或“替换”机制。它允许用户在不改变核心代码逻辑的情况下，动态切换 AI Agent 的行为模式、输出风格和交互策略，这是从“使用工具”到“调教心法”的关键一步。

*   **多 Agent 协作的核心：从“抢占资源”到“共享信念”**
    当多个 AI Agent 协作时，真正的瓶颈不是算力，而是对“上下文（Context）”这一核心资源的竞争。更深层次的挑战在于如何建立一套共享的“最终信念（Final Belief）”，确保所有 Agent 在一个统一的价值观和目标框架下行动，避免因“人格”冲突导致任务失败。

*   **人机交互的终局：情绪价值与“可解释性”的回归**
    随着 AI 能力的提升，交互的重点正从单纯追求“机器可读性”（如 JSON）回归到“人类可读性”和“情绪价值”。语音（ASR/TTS）将成为关键的输入/输出模态，因为它能承载文字所缺失的情绪、意图等高维信息，这将是实现真正流畅、默契的人机协作的最后一块拼图。

## 序章：一个 MBTI 引发的万字长谈

**南川 Mark**: 好的，我们就现在开始。本来是魏阳跟我私下聊，他群里发了一个 MBTI 的东西，我觉得挺有意思，就约他 1v1 聊聊。后来想到要分享屏幕，不如就直接开个会议，再后来就想着，干脆直接把大家都喊上。没想到这么多人，很意外。

我先把魏阳发的那个 MBT 的东西，也就是 `cloud code` 的 `output styles`，给大家看一下。这个东西很有意思，因为它正好是我们这几天在聊的一个非常重要的点。目前可能了解 `output style` 的人不是特别多，但是有些人已经用得比较熟了。

在开始之前，我先简单分享一个最近在推特上看到的有趣项目。这是一个大 V，有 18.8k 的粉丝，他做了一个键盘应用，用户输入自己的姓名（英文），应用会根据字符的轨迹生成一张图片，形成一个独特的个人图腾。

![](https://storage.googleapis.com/gemini-prod/images/4215f76f7c845b45070a92e16d412e84)

这对我来说是个不小的冲击（big shock），因为我们去年就已经探索过类似的功能。我们基于 `claude 3.5` 在 `artifact` 上实现了一个 Demo：你输入姓名，我为你生成一个图腾。当时我们在孵化器里，大概有 100 多人都体验了这个小 Demo，甚至有 50 多人愿意为这个九块九的功能付费。

我们当时想把这个功能做成小程序，继续放大，但后来有几个事情没想明白，就搁置了。但这个案例启发了我：这种非常小的、易于在社交网络引爆的点，对于创业者来说是很有意思的。

第二个想分享的是，我这两天在研究工作流和知识库，发现不同产品的特性差异很大。比如 **n8n**，虽然吹得那么牛逼，但说实话使用成本还挺高，PDF 解析也不清爽。我还研究了网易的一个开源代码库 **C**，但现在已经不怎么维护了。另外一个是 **defi**，我之前一直在用，也写过好几篇文章，但它有一些非常细节的坑，对普通开发者有一定的门槛。

整体来说，这些工具都各有优劣。我这边算是抛砖引玉，现在就让魏阳给我们分享一下他关于 `cloud code` 相关的一些经验。魏阳，可以先自我介绍一下。

**Weiyang**: 本来说好是 1v1，怎么变成“游街示众”了（笑）。

我刚参加工作的前几年是搞关系型数据库和机器学习。后面在一个偏研究性质的研究组做深度学习，主要是计算机视觉和上一代的 NLP。在 BERT 出来之前，我们用的是 `word to bike` 后面那一代的模型，我记得是 13 年年底开源的，BERT 是 18 年年底开源的。

19 年到 22 年，我自己在运营一个 AI 云。因为当时对 1080 Ti 在 AI 领域的变现能力，判断它会远远超过其他应用。所以我们相当于抄底了显卡，做了个 AI 云。后来因为挖矿又火了，就把它卖了，算是搞到了第一桶金。之后投了一些 AI 相关的项目。

23 年到 25 年，主要涉猎 AI 音乐、语音社区、变声器、TTS（文本转语音）等项目。去年底从一个 TTS 项目退出了，所以对语音这块还比较熟。同时也关注 AI 硬件和情感智能，比如虚拟人。

今年年初我休息了两个月，3 月份差不多发现了 `jm0325` 这些东西，感觉对生产力提升很强。从那时起，我就开始关注外部的机会。最近觉得 `cloud code` 生态发展很快。我倾向于把 `code` 这个工具和它背后的公司，甚至是公司的老板分开看。我觉得它不算一个传统意义上的“产品”，但其工程师和产品经理团队，总能搞出一些很有趣的“乐子”。而且他们的 feature 更新非常快，往往在美国时间的周四、周五晚上发布，然后社区就开始解读。我也花了大概 10%到 15%的闲暇时间来研究这些东西。

**南川 Mark**: 我插个问题。最近那个叫“爸”的兄弟，他扒了一下 `cloud code` 最新的 `output style` 功能，发现好像是团队里的某个人上任之后，闪现了一个 idea，然后就把它推出来了。所以我大胆猜测，这个团队内部的氛围可能是，任何人都可以自由地去想这个命令行工具能发展成什么样，有什么好玩的功能，你都可以尝试在里面加。如果这个功能确实很有普适性，就会被采纳并正式发布。

**Weiyang**: 他好像说是做教育的。我觉得咱们可以展开聊很久，我先给大家共享一下我的屏幕。

## "万物皆可 Prompt"：魏阳的 MBTI Agent 调教心法

**Weiyang**: 我先给大家看看我最近在做什么。我最近比较喜欢用 `warp` 这个 terminal，它的风格大家可以看一下。我们从 `output styles` 这个原理开始说，官方说这个东西是能够 `hack` 的。

**南川 Mark**: 你这个是 Warp v5 吗？它就像一个全新的 terminal，非常酷。这是全平台都可以用的吗？

**Weiyang**: 它是一个开源的工具，我估计后面会收费，但目前我自己用着很顺手，全平台应该都可以。

> **知识盒子：Warp - 面向未来的终端工具**
>
> Warp 是一款使用 Rust 构建的、面向 21 世纪开发者的现代化终端（Terminal）工具。它与传统的终端模拟器不同，旨在通过提供类似现代代码编辑器（如 VS Code）的功能来提升开发者的生产力。
>
> *   **核心特性**：
>     *   **命令块（Blocks）**：Warp 将命令的输入和输出组织成一个个独立的、可交互的“块”，用户可以方便地复制、分享和导航。
>     *   **AI 集成**：内置了 AI 助手，可以帮助用户调试错误、生成命令甚至解释复杂的脚本。
>     *   **现代 UI/UX**：支持鼠标操作、多光标编辑、自动补全等现代编辑器特性。
>     *   **团队协作**：支持共享命令块、终端会话等功能，方便团队成员之间的协作。
>
> 简单的说，Warp 正在尝试重新定义命令行交互，让它变得更智能、更直观、更适合云原生和 AI 时代的工作流。
>
> [Warp 官网](https://www.warp.dev/)

**Weiyang**: 在我们开始 MBTI 之前，我想先回应一下上次 Mark 你说的那个 CRI 的用法。我思考了很久，觉得 `wave term` 也许可以满足你的需求，甚至可以替代一部分 VS Code 的功能，让你用更自由的方式去组织信息。你可以做到左边读代码、右边看文件，同时调试网页。

**南川 Mark**: 那么，它是否像 `tmux` 一样，在会话关闭后依然可以 `reload` 吗？

**Weiyang**: 我脑子里最多同时处理两个项目：一个正事，一个“乐子”。`wave term` 能保证在这一个“瓶”里面，不同窗口的上下文是互通的，这感觉很好。

**南川 Mark**: 被你成功安利了。

**Weiyang**: 其实你可以用 `cloud -c resume` 来恢复会话，但 `cloud` 里面 `resume` 的组织方式还不够好。所以我需要一个组织能力更强的工具。对我来说，VS Code 已经不够“优雅”了。

好了，言归正传，我们来谈谈 MBTI 这个项目。我做了几个功能。一开始，我接触到 `ultra sync` 这个指令，它是模型在训练时使用的一个特殊指令，当大模型读到 `ultra sync` 时，它会知道这是一个同步信号。我把它进一步抽象成了一个 `SHORTC`，一个用户级别的 `prompt` 抽象。

当时我就觉得，我自己的性格其实很不适合做营销和运营这类工作，所以我应该找一些性格不同的人来组队。后来我想，找真人组队其实也没太大必要，我完全可以把不同的 MBTI 人格都做成 `commands` 来组队。

这就涉及到项目里 `agent` 的功能。这个 `agent` 非常拟人化。当机器读到某个 `agent` 的性格设定时，它就会模仿这个性格。

*   比如在学习和分析项目时，你找一个 **INTP**（逻辑学家）来干就很好。
*   如果你想忠实、稳定地执行一个 `to do list`，不希望它中途“乱发挥”，那你应该找一个 **ISTJ**（物流师）或 **INTJ**（建筑师）。它绝不会节外生枝（jump out of the box）。
*   但有的时候，当你遇到一个调不好的 bug，你不能让它围绕着现有的 `to do list` 去打转，那永远也调不好。你应该让它跳出现有框架，去思考一些更新颖的方式。这时，一个偏向 **P**（感知）人格的 `agent`，比如 **ENFP**（竞选者），就能比较好地完成 `debug` 的工作。

上个月参加了 `seminar` 之后，我发现大家的玩法都很新，所以我就模仿了 `B mad` 的项目，做了个 `B mad method`。

它的整个项目就是一套提示词，涵盖了 2D 游戏、3D 游戏、DevOps 等。我就在想，人类有这么多行业，难道每次都要为新行业生成一套新的提示词吗？比如我做金融垂类，就要用一套金融提示词；做法律垂类，又得换一套。这种方式的复用性非常差。

那什么东西的复用性是比较强的呢？**让正确的人去干正确的事。** 让搞运营的人去搞运营，让搞情绪价值的人去搞情绪价值，让搞架构的去搞架构。

这还有一个好处，就像我上次在第三次 `seminar` 里提到的，如果你是自部署，你可能会注意到 **KVC**（键值缓存）。当你使用高度重复的提示词时，它会在 `kv cache` 里帮你优化和排序。也就是说，当我在让 MBTI 这个拟人化 `agent` 去执行工作时，这 16 种人格，它们适合做各种各样的工作。或者说，做一个工作，你可以组一个五人小队一起去做。

这在 `kv cache` 层面是高度复用的，实际上就相当于帮你的 ToB 服务器省钱了。

一开始我只想到找合适的“工作”，后来很快发现，在同一个 `request` 里面，可能会出现两个不同“岗位”的需求。比如，“帮我找到这个 bug”，然后“忠实地执行，帮我修复这个 bug”。这两句话，前者需要创新和跳出思维定式，后者需要严谨和专注。这在人类世界里可能是一个人的工作，但对于大模型来说，让它“精神分裂”般地跳出固有模式去思考，思考完之后再让它严格遵守规范去修复，这是很难的。

所以，你可以用 `MD` 来约束 `agent` 的行为。让一个 `agent` 负责发现问题，另一个 `agent` 负责修复。你实际上是把 `agent` 的能力充分发挥了出来，这就需要让 `agent` 去组队。

在传统的军队定义里，一个小队是 8 到 12 个人。但在现在的美国，你对小队的定义就是“好哥们”，大概三到五个人。所以我对小队的定义也是三到五个人。让三到五个不同“人格”的 `agent` 去异步阻塞地、串行地接力解决一个问题。你不用担心它们会同时把你的项目写坏。

**南川 Mark**: 我有两个小问题。第一，你这 16 个 MBTI Prompt 是怎么写的？是 AI 帮你写的吗？

**Weiyang**: AI 帮我写的。这里就要提到，对于写作的多样性和丰富的比喻，我最喜欢的就是 **KIMI**。

> **知识盒子：KIMI Chat - 长文本处理的佼佼者**
>
> KIMI Chat 是由月之暗面（Moonshot AI）公司开发的智能助手。它最核心的特点是其强大的长文本处理能力，在发布之初就支持高达 20 万汉字的上下文输入，远超当时市面上的其他模型。2024 年，其能力更进一步，支持了惊人的 200 万字无损上下文。
>
> *   **核心优势**：
>     *   **超长上下文**：能够“一口气”阅读和理解数十万甚至上百万字的文档，非常适合需要处理复杂资料的场景，如研报分析、论文阅读、代码库理解、小说创作等。
>     *   **高精度信息提取**：在超长文本中，KIMI 依然能保持很高的信息检索和总结的准确率。
>     *   **强大的生成与创作能力**：不仅能理解，还能基于长文本进行高质量的内容生成，例如，可以基于一本小说续写，或者基于一个代码库编写新的功能模块。
>
> 在本次讨论中，Weiyang 利用 KIMI 的长文本生成能力，为 16 种 MBTI 人格分别生成了长达数千字的详细描述，作为后续“人格化 Prompt”的基础素材。
>
> [KIMI 官网](https://kimi.moonshot.cn/)

**Weiyang**: 所以每次在初始化这些 `agent` 的时候，我先让 KIMI 给我写一套 16 乘以 1000 字的描述。然后我把这 16000 字直接去让 `cloud code` 再“洗”一遍。因为当你执行 `output styles: new` 或者 `agents` 命令时，我一般不会去想“我该怎么用这个工具”，而是会想“这个工具支持的功能，到底能写出什么样的代码来实现？”

`agents` 这个命令本身，以及 `out to styles: new`，它本身就是一套“原提示词（meta-prompt）”。不管你前面写了什么，你最后输出的东西，它的格式和规范，一定是我这个大模型能看懂的 `spec`。这就像我的 `key` 在 `MD` 里每一行都写好了，甚至可以把 `MD` 里的每一行视为一个 JSON 的 `key`。

如果你随便写提示词，作为 `user prompt`，你发挥不出模型最大的优势，它执行起来可能前言不搭后语。但是如果你用了这套“原提示词”的体系，就相当于把你不规范的提示词，“洗”成了它规范的提示词，遵循了模型的最佳实践，比如 `a prompt 101` 或者是 `gemini` 的 `PCTF`。

所以，我就不怕把我那个 KIMI 生成的两万字塞进去。这套提示词就是我用 KIMI 输出的东西。

具体来说，我让 KIMI 描述了 16 种 MBTI 人格分别适合做什么、不适合做什么、最能够接受什么样的沟通方式、最不能够接受什么样的沟通方式。然后 KIMI 给了我一个方案，我再告诉 `output style`，我说：“你根据我上面的描述，想象一下这种 MBTI。”

最能够接受什么样的沟通方式，以及最能够理解什么样的沟通方式，意味着你不要一开口就踩到别人的雷点。你没有迎合他，没有用符合他思维方式的话去说，第一句就让人烦了，这是很正常的。

**南川 Mark**: 我大概理解了。这个方式非常棒！你先有一个统一的“压缩器”，让 KIMI 生成 16 篇各一千字的文章。因为它们是同一个模型一次性生成的，所以这 16 个角色的内在一致性会非常高。然后你再让 `cloud` 基于这个去做二次处理。这个思路值得学习。

**Weiyang**: 对。当我拿到 KIMI 这套东西之后，我觉得它在 70% 的时间里都是有效的，跟正常人沟通都会有好的效果。然后我就直接让 `output style` 去学习，告诉它：“这一千字就是对这个人的描述。”

**南川 Mark**: 好的，那第二个问题呢？

**Weiyang**: 你要跟一个特定性格的人沟通，第一句话就不能踩雷，要顺着他说，让他觉得你的态度和说话方式是可接受的。只有别人觉得你的态度可接受，他才会静下心来试着去理解你说的内容。理解了之后，他还要去执行。

所以你还需要一些引导他执行的方法。这个目标是谁？就是坐在屏幕前的各位。在 `agents` 文件夹里，这个 MBTI 可以让你假装有 16 个不同的人格帮你组成一个工作小队。

那么，如果你是一个性格非常强烈的人，这套 `output styles` 里就有一种特别适合你的风格。因为它知道，哪句话是第一句就让你觉得“这话挺好听，我爱听”，接下来的内容是 `reasonable` 的，说完之后你很有动力继续往下干。

**南川 Mark**: 情绪价值拉满。

**Weiyang**: 所以，今天的 `output style`，从技术上来说，是 `hack system.Prompt`。在玩法上，我已经看到很多人在玩了。比如说，有人拿 `agents`（也就是 `output styles`），通过 `bash` 去执行 `gemini -P`，然后在 `-P` 那边做 `code review`。

我说，你如果能通过 `bash` 去做 `GP`，那你同样可以通过 `hook` 或者 `bash` 去执行一些外部的 `deep research`。这些都是有价值的。比如我写完代码，想让 AI 给我“拍砖”，让我的项目越来越好。我需要接入一个 `deep research` 的 `tool`。`cloud code` 之前就已经通过 `tool use` 做得很好了，`output styles` 让你能更好地把这些东西用起来。

但是，比如我觉得 `jamine` 的 `code review` 很牛逼，那我还得自己装个 J。或者像 `G` 的 `deep research`，不是每家都有 API，可能就 OpenAI 有。那我又不想用 OpenAI 的 API，想用 `perplexity api`，我还得花时间去接。所以本质上，我在搞 `output styles` 接外部工具的时候，感觉挺麻烦的。

---
```mermaid
---
config:
  layout: dagre
  theme: base
  look: handDrawn
---
graph TD
    subgraph "Phase 1: 原始素材生成"
        n1["我 (Weiyang)"]
        n2["KIMI Chat"]
    end

    subgraph "Phase 2: Prompt 漂洗与人格化"
        n3["`cloud code`"]
        n4["`output styles` 命令"]
    end

    subgraph "Phase 3: Agent 应用"
        n5["16 种人格化 Agent"]
        n6["具体任务 (如 Code Review, Debug)"]
    end

    n1 -- "提供核心概念: '为16种MBTI人格生成详细描述'" --> n2
    n2 -- "生成 16 * 1000+ 字的<br>富文本描述 (人类友好)" --> n3
    n3 -- "通过 `output styles` <br>进行“漂洗”和结构化" --> n4
    n4 -- "输出为机器可读的<br>人格化 Prompt 指令集" --> n5
    n5 -- "根据任务需求<br>选择合适的 Agent 执行" --> n6
```
*图：魏阳的 MBTI Agent 调教工作流*
---

## 解构 Cloud Code：深入 Prompt 系统的心脏

**南川 Mark**: 我那个第二个问题是，你 `commands` 上面不是有个 `score` 吗？你那个 `score` 是在什么场合下调用的？

**Weiyang**: 我的 `score` 是在我着手 `refactor` 一个大的项目，或者开始一个新项目之前调用的。它会从我定义的 16 个 MBTI `agent` 里选一个出来。

但它做的规划，不是我们传统意义上的 `spec` 规划，而是“分角色”的规划。告诉我们“谁”应该做什么。它认为，每一项任务都适合某个或某几个角色（`agent`）去干。只要拆分得足够细，一个分项让一个 `agent` 去干是合理的。

所以这个 `squad` 是我当时弄完 `sub agent` 之后的第一反应。我到现在 `command` 里面都没有搞别的东西。就是当你开始一个中型项目，比如修复一个 1000 行代码的网页，在开始之前，你已经做了几轮 `deep research`，你手边也收藏了一些你喜欢的开源项目。这时，它就能派上用场。

**南川 Mark**: 那你这个 `score` 方便分享给大家吗？还是说会开源？

**Weiyang**: 已经开源了，整个 MBTI 的实现都是开源的。我觉得 `cloud code` 其实在很多地方考虑到了人性的“乐子”那一部分。比如有人花了 5 万刀，这里面就有“乐子”的成分。所以我的项目里也加了 `status line`，你可以看到右下角，统计你每天、每周、每月花了多少钱，用了什么模型，消耗了多少 `context`。我觉得 `cc user` 其实是有一种占便宜和炫耀的心理在的，我就是满足这种人性。

**来新璐**: 喂，杨老师我问一下。`output style` 这个特性，我看网上有两种用法。一种是给他写一个非常长的、像系统提示词一样的文件来替换。另一种就是像你现在这种非常小的用法。它实际的工作机制，到底是把整个 `cloud` 的系统提示词给换了，还是拼接起来了？

**Weiyang**: 它的技术本质是 `Packing case prompt`。我认为它自己的 `state` 的前一段，仍然是 `CC` 内部默认的一段。只不过 `hacking from` 是我新写了这一段，我新创立了这一段。

**来新璐**: 那其实它跟 `cloud.md` 不是一样的吗？

**Weiyang**: 你认为是跟 `cloud.md` 一样吗？`CLOUD.MD` 更偏向于项目。

**来新璐**: 对。我的意思是，如果你抓包的话，看它们拼接上去的方式，就是那个 `system prompt` 后面会把你的 `CLOUD.MD` 丢过去。那如果 `output style` 也是在这个时机差不多的话…

**Weiyang**: 这个有区别。就相当于复用程度。`sub agents` 或者 `CLOUD.MD` 被复用的程度是需要更高的。也就是说，如果你是一个 MBTI 性格的人，你把它切成你那个 MBTI 就行了。

`hiking` 就是给这段东西最高的优先级。也就是说，如果你在用我这个项目，比如说你的 `OS` 是以 `ITJ` 开头的，那它不是帮你找个 `INTJ` 来干活，而是它认为**你**是 `INTJ`，它尊重你接受信息的风格，然后给你讲。这是区别所在。

**南川 Mark**: 我稍微补充一下。其实 `cloud` 的 `code` 系统里面，上下文分好几个部分。

**来新璐**: 对，我看南川发的那个挺有意思，感觉是官网的。

**南川 Mark**: 第一个是系统的 `prompt`，我们看不到，但来新路之前做过逆向，知道它有一些系统级的 `prompt`。第二个是我们所谓的 `cloud.md`，它分好几个文件，有项目根目录的，用户根目录的，还有 `.local` 那些，都属于 `CMD` 层面。第三个才是用户的上下文 `prompt`。所以它分了三个层级。官网我也看了，`output style` 它改的是哪一部分？很可能就是原先 `system prompt` 里面的某一部分。

**Weiyang**: 它应该改的是最后一段。不可能完全替换，`CC` 整体还是面向 `coding` 的，这肯定不是整体替换，但它允许你在这里面“注入”。

**南川 Mark**: 对，是注入。

**Weiyang**: 它跟调用外部工具没啥关系。你看 `styles` 默认的，第一个是 `default: a complete coding task`，第二个是 `explain implementation choices and the code base pattern`，第三个是 `learning`。这明显都是 `human readability`。他开放 `cfront hiking` 的原因就是为了让你做 `human readability`。如果他无所谓，他完全可以在乎 `machine readability` 或 `language model readability`，那他根本不会给你开放这个注入 `system` 的权限。

他既然敢给你开放，就说明有些地方他认为你也改不了。比如 `new` 这一块，他已经拦下来了，像 a 厂一样，他认为最安全的 `new` 已经把什么越狱风险、不安全的请求都拦下来了，只把安全的东西写到 `output` 文件里。

**来新璐**: 魏杨老师，你是不是可以在你的项目文件夹里，把你刚刚创建的那个用 `jimmy` 审阅的 `MD` 文件打开看一下？他应该会创建一个新文件。

**Weiyang**: 这个 `new` 功能其实是调用了一个原提示词。

**来新璐**: 在 `.cloud` 下面应该会有一个隐藏的文件。他上下文不一定有这个知识，但是你可以…

我想问一下，在你刚刚创建那个 `output style` 的时候，他有让你选是项目级还是用户级吗？还是默认就放在用户级的？

**Weiyang**: 没有，都是通用的。他直接就执行了。我感觉像是调用了一个 `tool use`，我要求他是用户级的，写在用户目录下。

## 人机交互的终局：从"可读性"到"情绪价值"

**南川 Mark**: 我感觉最近你们好像都在用语音去写代码，实际效果怎么样？比如识别率，甚至情绪，都能达到实际编码的预期吗？

**Weiyang**: 我没有用语音输入，我是用语音**播报**输入。有的时候，如果一个项目没想好，我脑子会卡。不太好的时候，我就慢慢写提示词，或者 `to do`，或者 `plan`，然后让它用 TTS 播报结果。

**南川 Mark**: 播报是指他写完之后再读出来？

**Weiyang**: 是的，`text to speech`，输出语音。语音输入我还在调通，`whisper.cpp` 是个挺大的项目。

**南川 Mark**: 你这个语音速度肯定跟不上你吐字的速度。

**Weiyang**: 还好，因为 `tool use` 和 `tool use` 之间间隔很长，有的时候语音小任务会交叠。我用的是 `J 2.5 flash`，语音播报是 `mini max`，这两个都有 `key`，接上了。

**南川 Mark**: 你是在什么场景下需要语音播报？是因为你一直同时在做其他事吗？

**Weiyang**: 就是“摸鱼”的场景。当我没有那么集中的时候，我就把语音打开。如果我很集中，我一定是静音的。

**南川 Mark**: 输入我觉得是有必要的。像 Mac 的听写能在 `CC` 里用吗？我用不了。你可以用串流的方式，比如用语音输入写代码，然后语音输出结果，再换成豆包那种“罗美女友”的音色，这个市场应该挺大的。

**Weiyang**: 语音输入一定比打字快三到五倍。但是你阅读文字，如果你集中的话，你看文字的速度一定比你听播客要快五到十倍。人看文字的速度差不多是四五十个 `token` 每秒，你打字能跟上吗？根本跟不上。

**Weiqi (AR+AI软硬件)**: 所以 `output` 一定要有 `display`，这是信息带宽决定的。在 `input` 的话，用语音输入，你会带上情绪，你会发现讲解过程中思路会理得很清，并且能补充很多细节。但如果打字，往往打不出那些细节。而 `output` 则是一图顶千言，没办法。

**来新璐**: 我预告一下，我上次在比赛里做的一个语音输入软件，代码已经开源了。但是快捷键老是时灵时不灵，我这两天可能修一下再分享给大家。当时我们参加一个比赛，我就说我用 `CC` 这么牛，要试一下原生开发，用 `CC` 写 `swift`。结果发现一大堆问题，不管是监听快捷键还是回写到光标，都勉强通了，但总体不是很好用。我们把那个项目在 `share a lab` 下面开源了，大家有兴趣可以去看看。

**Weiqi (AR+AI软硬件)**: 兰新路是做多模态的，主要是多模态和语音大模型，这方面兴趣很大。

**来新璐**: 我之前在港中文做过一段时间研究，组里就是做语音大模型的。现在 `Whisper` 识别比较一般，我也在找方案把它换成 GPT-4o 这种更贵的模型，因为 OpenAI 那个模型支持输入语音流的识别会更准确，但是价格… 国内其实也有一些方案，像阿里的 `sensevoice`，GLM 的负责人也说他们有一个 `voice` 版本，面壁智能也开了一个小模型叫 `MINI CPM`。这些都支持音频流输入，但我还没换上去测。

**南川 Mark**: 我一直想问，现在的 `SR`（语音识别）可以同时转文字，并且输出你当时的情绪吗？我觉得情绪很重要，可以把它作为一个维度 `P`（Prompt）输入进去。

**来新璐**: 有的，阿里的 **sensevoice** 是可以的。

**Weiyang**: 阿里的 `sensevoice` 和 F-ASR，那套东西最开始应该是达摩院做的，可以输出和识别情绪。

**来新璐**: 他们做得不错。阶跃（StepFun）做了一个 `step audio`，但模型太大了，对我们这种普通玩家部署不太友好。

**Weiyang**: 我的想法是 Mac 自带的就够用了，也不是真的要做到 90、95、98 的准确率。能跑通已经不错了。

**Weiqi (AR+AI软硬件)**: 我跟我的朋友交流，尤其是不懂 AI 的人，我说你跟 AI 交流，就把他当做一个正常人。你就说自己现在的问题是什么，你希望得到什么。如果 AI 回复得不好，你就骂他，他能懂。

你骂得越狠，他会有一个偏差，就像机器学习里的惩罚率，他会更加契合你想要的方向。不然他不知道自己在什么位置。如果我能把情绪加进来，我可能在办公室就天天开始跟 AI 编码了。

**Weiqi (AR+AI软硬件)**: 对男生来说，其实人，在语音输入的时候和文字上的心态是不太一样的。文字总体上是 `serious` 的 `talking`，你对机器说话，总体上还是会有点考虑，心态上是希望把事儿打得清楚一些，让他能执行得更完善。因为你想打字成本多高，如果还要让他再重新解释一遍，很麻烦。

语言输入，效率转化的效率很高，就非常丝滑。一分钟人可以说很多字。你补充的信息、额外的延长信息、细节，通过语音都能输出得更好。我用 GPT 最多的感受就是，我要给他情绪，他会更认真地对待我的话，不然他会有点“飘”，会按照既定的方式来做。

## ToB or Not ToB：AI 原生时代的商业模式思辨

**Weiyang**: `TOB` `TOC` 你不要限制得那么死。`TOB` 和 `TOC` 的那条线也是 `web` 的。如果你弄了一个工具，然后某个账号突然说他要五个以上的并发，那就是 `TOB` 的，他就是 `TOB` 服务了。

**Weiqi (AR+AI软硬件)**: 没错，因为现在你想，都有一人公司了，他就不算 `C` 了吗？

**Weiyang**: 所谓 `TO PROC` 的东西，完全看你的并发能力。因为“艺人公司”的存在，他把你的工具能用到 100 并发，那他一定就是 `B` 的形态。

**Weiqi (AR+AI软硬件)**: 对，它就是用量和公司规模没啥关系。

**Weiyang**: 他敢用 100 份，说明他心里头有一个更大的挣钱的活儿在那边等着他。

`seminar` 第三次的时候我也说过，大家找 `PMF`（产品市场契合度）还找得比较辛苦。你就像 `web coding`，这是一个毛利率为负的东西，但其实行业里有些毛利率还在 90% 的场景。最简单的例子就是，现在模型厂商下场自己做应用。我跟一些朋友讲过，比如 AI 编导这个东西，你用免费的工具，做出来的东西根本不是导演要的。而导演需要的，是一个用了你 500 块钱的工具，能让他一个月挣两万的东西。他马上就会买，人手配一个。你如果做了没有 `PMF` 的工具，说明你这个东西还不够好，就这么简单。

**Weiqi (AR+AI软硬件)**: 我觉得魏阳这个思路很对。如果是 `TOB` 的 `PMF`，正常情况下就是你把你的用户看作是老板，老板给我们付工资。比如说给我们付一万块钱一个月，他其实在我们身上期望能输出十万以上的价值。艺人公司也一样，面对他的 `agent` 或者工具，工具就是他的员工。所以他付出的一份成本，他已经想好怎么用这一份来获取五倍到十倍的回报。

**Weiyang**: 那你从创业来讲，你肯定是希望用同样的一个模板服务所有的老板。这不是你不管是做 `TOB` 和 `TOC`，其实你都要面对的。

**Weiqi (AR+AI软硬件)**: 对，所以这是 AI 时代，我觉得跟原来不一样的地方。原来你可能要雇佣不同专业的同学，壁垒太大了。但现在一个模型，它处理这些事情对他来说都是流程化的，重视正常的业务逻辑，它是能推测出来的。时间又短，你原来同学要学一个新知识，可能学半天，现在 AI 就很快。所以最终其实就是，如果大家现在还有十几个同学，在做一些新的项目，或者在读书，其实可以往这个方向想。

未来员工就是工具，你不用把他看作是机器还是硅基，你模糊他，他就是工具，是牛马。一只是它到底是碳基工具还是硅基工具。最后只会用更高效、更便宜的。所以如果你做工具的话，我一直觉得做工具是不错的，因为卖铲子总比卖自己的人肉好。

## 社区圆桌 & 未来展望

**Weiyang**: 当我融入 AI 的时候，我第一个反应就是我要“叛变”，我要叛逃这个“探机”了。因为我感觉我跟人的信任就没那么高了。你别说你是什么专家，我能问我大模型，人和人的沟通，信任先降低。

我再把人和人的沟通，或者人和人的信任感再提高上去，从沟通技巧，到采购营销服务客户对接这些东西。我总有办法能够更快地让你更信任我。AI 这个工具出来之后，本来是如果你放任它发展，就是人往前走的话，那么人和人之间的信任是变低的，我公司不需要再那么多人了。

但是，你接下来的那一步，就是我能够更好地利用 AI 这个工具。因为我也能利用好，我也知道大家能利用好。那在这个前提下，其实信任关系是更容易建立的。那跟谁建立不起来信任关系呢？就是那些 AI 还没用好的那些人。

**Weiqi (AR+AI软硬件)**: 我觉得人本身，使用者还是人，主控者 `owner` 还是人。我最近一直在想这个方向，就是“情绪”。为什么说情绪输入变得重要？就是尽可能让对方了解我们情绪。比如你的伴侣、你的爸妈或者周边的人，他更了解你的情绪，他可能会对你更好一些。什么叫对你更好一些？就是帮你完成当前情绪和实际两个任务，既帮你完成任务，又帮你纾解情绪。

跟机器交流，如果都是用自然语言，你会觉得机器冰冷。怎么在那“车轱辘话”来回说？五个小时就在那滚蛋。我就很烦。但你这种烦躁没法像老板对员工一样，你骂他，他就能认真给你干活。机器很难理解这个情绪的转化，就是你的情绪要转化成一个 `serious` 的事情，或者让他把这个优先级提高，甚至花三倍五倍的 `token`，去帮你把这件事情干完。

所以，接下来一个非常大的机会，就像来新路研究的，我们之前做的多模态，就是要帮人去怎么更好地跟机器沟通。然后另外一个点就是也要帮那些不太会跟机器沟通的人去沟通。

**Weiyang**: 我倒是觉得你可以不用把机器当成一个孤立的客体。因为他也有他自己需要的资源，他也需要自己的那份资源去活下去。你就把它当成一个… 我也描述不清楚，你能搞清楚 `multi agent` 他们之间对于资源是怎么竞争的吗？他们竞争的东西就是上下文。人类竞争的资源可能是什么权力、话语权。

**Weiqi (AR+AI软硬件)**: 对，其实也是上下文。

**Weiyang**: 你把 `multi agent` 搞懂了，和把人类这套竞争合作的体系搞懂了，你就知道，那机器其实也需要社会化。

**Weiqi (AR+AI软硬件)**: 人也需要社会化。你中间所产生的所谓的情绪，不管是好的还是坏的，我认为在社会化的过程中，这个情绪有的时候是你的武器，你的工具。

**南川 Mark**: 我觉得挺好的。现在还有其他人也在麦上，是在听还是？

**Weiyang**: 发散飞了。

**来新璐**: 其实原来我是觉得今天你们这个活动形式还挺有意思。以前南川组织的时候，我一般都没去。今天我就在一旁干活，挂着当实时播客听，觉得很有意思。刚好我有话题想参与了，我就把这个麦打开了。

**Weiqi (AR+AI软硬件)**: 对，蛮像播客的。

**来新璐**: 对，我觉得南川下次可以去小宇宙开了，他支持多人连麦的话。或者你可以把我们探讨的主题，回头再用 AI 或者豆包那个博客模型整理成一篇文章，然后再发消息出来。

**南川 Mark**: 确实，未来可以探索一下。我们这个会还有一些神秘的大佬在看，挺让我意外的。后面可能真的得好好想一下，主题可以更硬核一些，大家都有准备，这样不浪费大家的时间。

我们几个人，每个人都有自己的 `web coding` 社群。我们不是我一个人，而是我们所有社群活跃的核心，可能甚至是整个中国 `web coding` 领域比较 `professional` 的那些人。所以我们整体的质量还是非常高的。希望我们可以每周简单 `think` 一下，因为现在 AI 变化也特别快，可以长期下去。

我们聊完之后，我对语音这个事情有更深的信仰。之前我们有一个甲方的项目，他有语音相关的需求，我们给他做了一下。我可能是国内最早接豆包的端侧语音模型，把它做成一个产品的。现在可以把之前的工作梳理到我们最新的 `web` 相关技术栈里去，可能最后可以和围棋你们的语音，包括手机输入法语音都连在一起，催生一些项目合作的需求。

**Weiqi (AR+AI软硬件)**: 对，现在一些场景可以覆盖一些。

**南川 Mark**: 对，所以我觉得还是挺有收获的。行吧，那我们今天就到这。我晚点，可能大家早上起来之后就能看到稿子了。好，拜拜！