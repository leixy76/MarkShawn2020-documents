

> AI Agent 如人，不仅应有其“能”，更应有其“格”。当代码不再冰冷，当工具拥有性格，我们正站在一个全新人机协作范式的起点。

### Key Insights

### **MBTI meets AI**

将 16 种人格注入 AI Agent，构建“性格驱动”的开发团队，以应对不同类型的工程挑战。

### **Hack the Prompt**

`output style` 不止于风格，更是对 Claude 系统提示词的一种深度“注入”，开辟了提示工程的全新维度。

### **人机交互新范式**

从命令行到语音，再到情感计算，我们与 AI 的协作正在超越纯粹的文本，迈向更高效、更符合人性的多模态未来。

### **工具的哲学**

开源、生态与商业模式，AI 时代的开发者工具正在经历一场深刻的演进，开放性和可组合性成为新的核心竞争力。

## 缘起：一场由 MBTI 引发的头脑风暴

**南川 Mark**: 大家好，今天这个局的缘起其实很有意思。我在群里看到 Weiyang 发了一个关于 MBTI 的内容，觉得非常有启发，就想拉着他一对一聊聊。本想着只是两人交流，后来考虑到可能需要分享屏幕，索性就开个会议，没想到最后来了这么多人。

我先把 Weiyang 发的那个 Cloud Code（*Claude 旗下 AI 编程工具，后文简称 CC*）的 MBTI 相关内容分享出来。`output style` 是我们这几天一直在聊的 CC 的一个核心功能，目前可能了解的人还不是特别多，但已经有人玩得很熟了。今天我们就借这个机会，深入聊一聊。

## 核心揭秘：Weiyang 的 MBTI Agent 项目

**Weiyang**: 我刚参加工作的前几年主要做关系型数据库和机器学习，后来转向深度学习，主要在计算机视觉领域。BERT 是 18 年底开源的，在那之前我主要做 Word2Vec 相关的工作。19 年到 22 年，我抓住机会“抄底”了一波显卡，运营了一个 AI 云，算是掘到了第一桶金，后来也投资了一些 AI 相关的项目。23 年到 25 年，我涉猎了 AI 音乐、语音社区、变声器和 TTS 等多个项目。

今年以来，我发现像 Claude Code 这样的工具，生产力非常强，生态发展也很快。我花了大约 10% 到 15% 的闲暇时间去研究它。我觉得 CC 这个工具和它背后的公司，甚至和公司的老板，都应该分开看。它本身可能不算一个传统意义上的“产品”，但团队里的工程师和产品经理总能搞出很多有意思的“乐子”。

**南川 Mark**: 我插个问题，最近是不是有个叫“爸”的开发者，他扒了一下 CC 最新的 `output style` 功能，发现好像是团队里的某个人上任后，闪现了一个 idea，然后就把它推出来了？我大胆猜测，在 CC 团队内部，所有人都可以自由地为这个命令行工具贡献想法和功能。只要这个功能具备普适性，就可能被采纳并正式发布。

**Weiyang**: 对，我看到介绍说他是做教育的。这个团队的推进氛围确实很好。

回到我的项目，核心就是把 MBTI 的人格类型做成 `commands` 来组建虚拟团队。这其实源于我自己的一个观察：我的性格并不太适合做营销和运营这类工作，所以就想，是否能找到一些性格不同的人来组队？后来发现，找真人组队其实没那么必要，我完全可以创建一套 AI Agent 来实现。

### 第一步：用 Kimi 生成 16 型人格的“圣经”

**南川 Mark**: 我有两个小问题。第一个，你这 16 个 MBTI 的描述是怎么写的？是 AI 帮你写的吗？

**Weiyang**: 对，这里我要特别提到 Kimi。对于写作的多样性和丰富的比喻，我最喜欢的就是 Kimi。

我初始化的第一步，是先让 Kimi 给我写一套 16 型人格的详细描述，每种人格大约 1000 字。这样我就得到了一个 `16 * 1000` 字的知识库。

**南川 Mark**: 我大概理解了，你这个方式非常棒！相当于你先用一个统一的“压缩器”（Kimi），生成了 16 份总计一万六千字的描述。因为它们由同一个模型一次性生成，所以这 16 个角色的内在一致性非常高。然后你再让 Claude 基于这个高质量的文本库去进行后续操作。

**Weiyang**: 完全正确。因为我自己记不清，也无法准确地描述每种人格的优势和劣势。所以，我先让 Kimi 结合网上的分析，明确告诉我每种人格的优劣势、适合与不适合做什么、最能接受和最不能接受的沟通方式是怎样的。

Kimi 会给出一个非常详尽的方案。我拿着这份方案，发现即使是和真人沟通，效果也能提升 70%。比如说，你平时和某个 MBTI 类型的人交流，第一句话就可能踩到对方的“雷点”，这很正常。因为你没有迎合他的思考方式。而通过 Kimi 的分析，你可以学习到如何用对方最能接受的方式去沟通。

当对方觉得你的态度和说话方式都非常舒服时，他才会静下心来理解你说的内容。理解之后，还需要引导他去执行。

### 第二步：`output style`——将性格注入 Claude

**Weiyang**: 我将 Kimi 生成的这 16 份 `1000` 字的描述，直接喂给 `output style`。我告诉它：“这段 1000 字的文本，就是对这种 MBTI 人格的精确描述，请你基于此进行想象和模拟。”

`output style` 本身支持一种类似 `hack` 的用法。`agents` 这个命令以及 `out to styles: new` 这个命令，其本质就是一套“原提示词”（meta-prompt）。无论你输入的自然语言是什么样子，最终输出的格式和规范都必须是这个大模型能看懂的 `spec`。这就像我的 `key` 里预设好了一个 `json` 结构，规定了 `output styles` 该用什么 `style`，不该用什么，例子是什么。

如果你随便写，问题也不大，因为 `output style` 本身就鼓励 `hack`。但实际上，很多大厂的模型对 `prompt` 是有规范的，比如所谓的 `prompt 101`。如果你随便写的提示词不符合规范，作为 `user prompt`，其效果就会大打折扣，甚至可能导致模型“前言不搭后语”。

而我通过这套“原提示词”，就相当于把不规范的自然语言“洗”成了模型能理解的、遵循其内部规范的提示词。比如遵循 `a prompt 101` 或是 Gemini 的 `PCTF` 规范。这个过程就是角色化、任务目标化和样例化的过程。

### 第三步：组建 AI 小队 `squad`

**Weiyang**: 在这个项目里，`agents` 文件夹下的 MBTI 描述，可以让你假装拥有一个由 16 个不同人格组成的虚拟工作小队。如果你本人的性格特质非常强烈，那么这套 `output styles` 里，就会有一种风格是特别为你——也就是屏幕前的用户——量身定制的。因为它知道，哪句话是你的“心头好”，第一句就能让你觉得“这话我爱听”。

后面的内容也会让你觉得 `reasonable`，听完之后你就会充满动力去执行你的项目。

**南川 Mark**: 这就是把“情绪价值”拉满了。

**Weiyang**: 在军队的定义里，一个小队是 8 到 12 个人。但现在，比如在美国，小队的定义更像是“好哥们”，大概三到五个人。所以我对小队的定义也是三到五人，让三到五个不同“人格”的 AI 去解决同一个问题。

整个过程是串行和异步阻塞的，所以你不用担心几个 agent 同时修改代码把你的项目搞坏。这就像你同时打开两个窗口写代码，也大概率会去写不同的模块。如果真要处理同一件事，就让不同的 agent 接力完成。

这个 `squad` 的概念是在我完成了 `sub agent` 之后，第一个反应就是需要一个小队。比如，当你准备开始一个新项目前，可能已经做了几轮的 `deep research`，手头也收集了一些你喜欢的开源项目。这时，你需要完成一个中等规模的工程，单纯修复一个网页可能只需要 1000 行代码，但一个中型任务就复杂得多了。

**南川 Mark**: 那么 `score` 这个命令，在什么时候会用到呢？

**Weiyang**: `score` 主要用在我准备重构一个大项目，或者开启一个新项目之前。它会从我定义的 16 个 MBTI 类型里挑选一个合适的角色。

但它做的并不是我们传统意义上的 `spec` 规划，而是“分角色”的规划。也就是说，它会规划“谁”应该做什么，而不是具体“做什么”的细节。这和我们去写一个绿色的或者具体的 `spec` 是有区别的。

我认为，一个项目里的每一项任务，其实都适合某一个或某几个“角色”去完成。只要任务拆分得足够细，让一个角色去干一个分项，就是合理的。

### 知识点：MBTI 与 AI Agent 的内在逻辑

通过 Weiyang 的分享，我们可以构建一个清晰的工作流，来理解他是如何将 MBTI 理论与 Claude Code 的功能相结合，创造出一种全新的 AI 协作模式。

这个流程的核心在于，通过人格化的注入，将通用的 AI 模型转化为具备特定行为模式和沟通风格的专业 Agent，再通过“团队协作”的模式，来解决单一 Agent 难以应对的复杂问题。

```mermaid
---
config:
  layout: dagre
  theme: base
  look: handDrawn
---
graph TD
    subgraph "Phase 1: 知识库构建 - Knowledge Base"
        A["1. 使用 Kimi 生成"] --> B{"16 种 MBTI 人格的千字描述<br/>(沟通风格、优缺点、工作模式)"};
    end

    subgraph "Phase 2: Agent 人格化 - Personalization"
        B --> C["2. 注入 Claude Code 的<br/>`output style` 或 `agents`"];
        C --> D["产出: 16 个具备鲜明<br/>人格特质的 AI Agent"];
    end

    subgraph "Phase 3: 团队协作与任务执行 - Collaboration"
        D --> E{"3. 定义任务<br/>(e.g., Debugging, Refactoring)"};
        E --> F["4. 使用 `squad` 概念<br/>组建3-5人的 AI Agent 小队"];
        F --> G["例如: INTP (分析) + ESTJ (执行)"];
        G --> H["5. Agent 协同工作<br/>(串行 & 异步阻塞)"];
        H --> I["产出: 解决复杂工程问题"];
    end```

这个框架不仅是一个技术实现，更是一种方法论的探索。它试图回答一个核心问题：我们能否通过模拟人类社会的协作模式，来提升 AI 系统解决复杂问题的能力？Weiyang 的实践给出了一个肯定的答案。

## 技术深潜：`output style` 的工作原理

**来新璐**: 我想问一下，`output style` 这个特性，我看到网上有两种用法。一种是写一个非常长的文件，像系统提示词一样去替换它；另一种就是像你现在这样非常简短的用法。它的实际工作机制，到底是把整个 Cloud 的系统提示词替换掉了，还是拼接进去了？

**Weiyang**: 从技术本质上来说，是 `Packing case prompt`。我认为它自身的 `state` 中，前一段仍然是 CC 内部默认的一段。只不过，`hacking from` 意味着我新写了这一段，我新创立了这一段。我这段儿是 `cpr` 的一个子串，就像 `a+2b` 的感觉，变成了 `a1` 段 `b1` 段。所以它的 `row row R` 就变了。

**来新璐**: 这样的话，它和 `.cloud.md` 文件不是一样的吗？

**Weiyang**: 有一个区别，就是复用程度。`sub agents` 或者 `.cloud.md` 被复用的程度需要更高。而 `output style` 的复用级别是“每次”级别的。如果你是一个 MBTI 性格，你就可以把它切成你那个 MBTI 的样子。

**南川 Mark**: 我来补充一下。整个 Cloud Code 的系统里，上下文分为好几个部分。
1.  **系统 Prompt**: 这是我们看不到的，来新璐之前也做过逆向工程，它确实存在。
2.  **Cloud DMD**: 也就是我们所谓的 `.cloud dmd` 或 `.cloud.md` 文件，分布在项目根目录和用户根目录等不同位置。
3.  **用户上下文 Prompt**: 这是用户输入的具体指令。

`output style` 修改的是哪一部分呢？它可能并不是完全替换，而是把原先系统 Prompt 里的软件工程部分给“关掉”，然后把新的内容“注入”进去。

**Weiyang**: 对，它不能是整体替换，CC 的核心还是面向 `coding` 的。它允许你在这里面“注入”。但这个和调用外部工具（如 `code review`）没关系。你看 `styles` 里的 `default` 选项，就是一个 `complete coding task`。第二个是 `explain implementation choices and the code code base pattern`，第三个是 `learning`，这明显都是 `human readability`。

它之所以敢让你做 `cfront hiking`，就是为了让你实现 `human readability`。如果它在乎的是 `mc piability` 或 `lm readability`，它根本不会开放这个注入权限。

**来新璐**: 魏杨老师，你能在你的项目文件夹里，把你刚刚创建的那个用 `jimmy` 审阅的 MD 文件打开看一下吗？它应该会创建一个新文件。

**Weiyang**: `new` 这个功能，其实是调用了一个“原提示词”。

**来新璐**: 在 `.cloud` 目录下应该会有一个隐藏文件。它不一定知道上下文文件的知识，但是可以做到。我想问一下，在你刚刚创建 `output style` 的时候，它有让你选择是项目级还是用户级吗？还是默认就放在用户级？

**Weiyang**: 没有，都是通用的。它直接就执行了，感觉像是调用了一个 `tool use`，我要求它是用户级的。

这场关于 `output style` 原理的讨论，揭示了 Claude Code 设计上的一个核心思想：**分层与注入**。它的提示词系统不是一个铁板一块的整体，而是一个由多个部分组成的、可扩展的结构。

```mermaid
---
config:
  layout: dagre
  theme: base
  look: handDrawn
---
graph TD
    subgraph "Claude Code 提示词结构 - Prompt Architecture"
        A["Level 1: System Prompt (隐藏)"] --> B["Level 2: .cloud.md (配置级)"];
        B --> C["Level 3: User Prompt (指令级)"];
    end

    subgraph "注入机制 - Injection Mechanism"
        D["`output style` / `agents`"] -- "注入/修改" --> A;
        C -- "触发执行" --> A
    end

    A -- "影响最终行为" --> E["LLM Core"];
```

这个结构的设计哲学，类似于操作系统的内核空间与用户空间。`System Prompt` 是内核，定义了核心能力；`.cloud.md` 是配置文件，允许项目级的定制；而 `output style` 则提供了一种类似 `hook` 或 `API` 的机制，允许用户在运行时动态地、临时地修改系统行为，而无需触碰核心代码。这正是其“可 `hack` 性”的根源。

## 交互的未来：从键盘到语音与情感

**Weiyang**: 我个人没有用语音输入代码，而是用语音“播报”输入。有时候项目没想好，脑子会卡住，这时就不太适合用语音。但可以用它来慢慢写提示词，或者写 `to do`、写 `plan`，然后让 TTS 把结果播报出来。

**南川 Mark**: 播报是指它写完之后，用语音读出来吗？它的整个处理过程，包括最终结果，都是用语音播报吗？

**Weiyang**: 是的。`post tool use` 也就是每次调用完一个库或一个 `to-do` 后，它会围绕这次 `tool use` 的输出，给我一个 `summary`。

**南川 Mark**: 那你这个语音速度肯定跟不上你思维（吐字）的速度。

**Weiyang**: 还好，因为 `tool use` 之间间隔很长，有时候语音任务会交叠。我用的 `summer` 是 J 2.5 flash，语音播报是 `mini max`，这两个都有 `key` 可以直接对接。

**南川 Mark**: 你是在什么场景下需要语音播报？是因为你同时在做别的事情吗？

**Weiyang**: 就是在“摸鱼”的场景。当我没那么集中的时候，就会把语音打开。如果我很集中，肯定会静音。

**Weiqi (AR+AI软硬件)**: `output` 一定要有 `display`，因为信息的带宽会大很多。但在 `input` 端，用语音输入会带有情绪，我平时用 ChatGPT 也是用语音输入，你会发现，在讲解过程中，能把自己思路理得很清，并且能补充很多文字打不出来的细节。

**Weiyang**: 我最近也发现了一个叫 `whisper input next` 的项目，是小红书的一位网友开发的。它把 `gpt-4o` 做了优化，比如我说了一长段前言不搭后语的话，`GPT-4o` 会帮我美化，把两个不相干的话题串联起来。

**南川 Mark**: 这非常有意思。它可以在两个方向上优化：
1.  **内容层面**：把我本来不清晰的语言表达，翻译成更严谨、能结合上下文的文本。
2.  **AI 理解层面**：把优化后的文本再送给 AI，AI 的回复效果会更好。

**来新璐**: 我上次比赛时做了一个类似的软件，已经开源了，是用 CC 写 Swift 的原生开发。它会调用 `mini` 这种特别小的模型，快速帮你转写，但总体还不是很好用。目前我觉得 `vis` 识别比较一般，也在找方案把它换成 GPT-4 这种更贵的模型，因为它支持输入语音流，识别会更准确。

国内也有一些方案，比如 GLM，我上次和他们的算法负责人交流过，他们有个叫 `GRM-4` 的 `voice` 版本。还有面壁智能开的一个小模型叫 `MINI CPM`。这些都支持音频流输入。

**南川 Mark**: 我一直想问，现在的 SR（语音识别）技术，能不能在转文字的同时，把当时说话人的情绪也一并输出，然后把情绪作为一个参数（P）传进去？我觉得情绪非常重要。

**来新璐**: 可以的，阿里的 `SenseVoice` 就可以。

**Weiyang**: 阿里的 `SenseVoice` 和 F-ASR 吧，最早应该是达摩院做的，可以输出和识别情绪。

**Weiqi (AR+AI软硬件)**: 如果把情绪加进来，我在办公室可能就会天天跟 AI 去编码了。对男生来说，人在语音输入时和文字输入时的心态是不一样的。语音总体上是 `serious talking`，而文字更像是 `chatting`。你对机器说话时，心态上会希望把事情讲清楚，让它能更好地执行，因为打字的成本很高。

**南川 Mark**: 我想到一个场景。当大模型回复的结果不符合我预期时，如果是语音交互，我可能就会脱口而出：“你怎么能这么回？”但如果让我打字，等我准备打字时，情绪可能已经平复下来了，最后只会打一个“对”。

**Weiqi (AR+AI软硬件)**: 这就是效率的区别。语音的 `input` 带宽比文字高，但 `output` 却比文字低十倍以上。这就是为什么我们的眼睛需要 `display`。从碳基生物本身的核心思维模式来讲，我们在讲述一件事情的时候，很少有人能一次性把逻辑讲得非常清楚，我们都是在不停输出的过程中整理自己的逻辑。但打字不一样，打字是一直在思考的结构化语言。

这场关于语音交互的讨论，实际上触及了下一代人机交互的核心议题：**如何超越文本，实现更高带宽、更人性化的信息交换？**

1.  **输入端 (Input)**:
    *   **高带宽**: 语音能承载比文本更丰富的信息，包括内容、情绪、语气、停顿，更接近人类的自然交流方式。
    *   **思维同步**: 语音输出更接近思维的速度，有助于在“流动”状态下进行创造性工作，而不是被键盘输入打断。
    .
2.  **处理端 (Processing)**:
    *   **情感计算**: AI 不仅需要“听懂”内容，更需要“看懂”情绪。情绪作为一种重要的元数据，可以极大地影响 AI 的行为和响应，使其从一个冷冰冰的工具，变为一个善解人意的“协作者”。
    .
3.  **输出端 (Output)**:
    *   **多模态**: 语音播报（TTS）适用于“摸鱼”、辅助或多任务场景，而视觉呈现（Display）依然是高密度信息消费的主流。未来的理想形态，很可能是基于场景自适应切换的多模态输出。

这个趋势预示着，未来的 AI 工具将不再仅仅是命令行的延伸，而是更加深度地融入我们的工作流，以听、说、看等多种方式，与我们进行无缝的、高情商的协作。

## 开发者工具的生态演化

**Weiyang**: 我之所以把 TDS（Text-to-Speech）接下来用的是 `mini M tts`，然后用的是我老婆的夹子音，把它塞到 `MINI M. Mini Max`。

**来新璐**: 你别说，MiniMax 现在招人挺积极的。不过它的 API 很抽象，大模型的 API 基于 OpenAPI V2 协议，SK 是一大串，调试起来有莫名其妙的错误。

**Weiyang**: 我在 MiniMax 群里吐槽过，说它的 `key` 比我的命还长。我对它 API 的评价是，别人家的 API 我用 web 方式，五到八分钟就能改好；他家的，我得改俩小时。

**来新璐**: 我跟他们技术负责人私聊过，说 API 太抽象了，能不能跟别的模型供应商兼容一下。他们回复说“你们开发者自己改一下不就好了嘛”。我当时就想，你们改一下，外面几百万开发者就不用重复劳动了。

**Weiyang**: 其实如果想做东西，可以直接申请他们的开发者 `bonus`，要免费包或者要折扣，都是可以谈的。当你做到几万用户，并且在持续地跑、产生数据，你完全可以跟他说：“你看我这几万用户，赶紧给我打个骨折。”他内部利润率很高，直接给你打个骨折是完全可能的。

**来新璐**: 我觉得你说得对。大模型厂商内部的 `tok` 率和利润率都挺高的，不然也不会每次都去补贴大家 200 美金了。

**Weiyang**: 他们很怕开发者手里没活儿干，天天一堆乐子活。去年 MiniMax 给做儿童玩具的厂商之所以给那么多优惠，就是因为我当时搞 TTS 认识了一堆做这种厂商的。

**Weiqi (AR+AI软硬件)**: 他怕你跑了。现在接口统一的话，移植成本很低，很容易跑掉。

**Weiyang**: `cloud code` 面前人人平等。你能做的，我也能做。我要把我的东西复用起来，它是围绕项目和项目类型（比如 2d/3d 游戏）来做的。如果用 B 麦克风感觉更爽，那他做的也不错。至少，他把搞运维或者 2d/3d 游戏的用户体验做得很好，直接用就行。

**南川 Mark**: 他理解的项目流程和拆分，和你理解的，基本上是一致的。

**Weiyang**: 对，那就可以直接用。但我做的这个东西，更希望它通用一点。我不管你是 2d 还是 3d 游戏，前面可以接一个 `deep research`，后面可以接一个 `S`，这样去分工。它和围绕具体行业的 `spec` 是两个不同的维度，都需要，但我没有局限在具体行业。

这场关于工具生态的讨论，反映了 AI 时代开发者工具正在发生的深刻变革：

*   **从封闭到开放**：传统的 IDE 或工具链往往是封闭的、一体化的。而以 Claude Code 为代表的新一代工具，则更加强调开放性、可组合性和“可 `hack` 性”。开发者不再是单纯的使用者，更是生态的共建者。
*   **API 成为新的战场**：模型本身的能力逐渐趋同后，API 的设计、文档、易用性和商业政策，成为厂商争夺开发者的核心竞争力。抽象、难用的 API 会直接劝退大量开发者，而友好、兼容的 API 则能快速构建起繁荣的生态。
*   **从 ToC 到 ToB 的模糊边界**：Weiyang 提到，当一个工具的并发使用超过五个，它就具备了 ToB 服务的属性。一人公司、小型敏捷团队的兴起，使得个人开发者（ToC）和企业用户（ToB）之间的界限越来越模糊。工具的设计必须同时考虑个人效率和团队协作。
*   **通用性 vs. 专用性**：是做一个能适配所有场景的通用工具，还是做一个针对特定领域（如 2D 游戏开发）深度优化的专用工具？这没有标准答案。Weiyang 的选择是追求更高的通用性，而 Claude Code 本身则在专用领域提供了很好的实践。这两种路径的共存，共同构成了丰富的工具生态。

## 终局思考：人与 AI 的协作边界

**Weiqi (AR+AI软硬件)**: 我感觉 AI 的发展这么快，我的第一个反应就是要“叛变”。我要叛逃这个“探机”了。因为我感觉人和人之间的信任没那么高了。我完全可以去问大模型，人和人的沟通与信任反而先降低了。但下一步，就是我能够更好地利用 AI 这个工具。我知道大家都能利用好，在这个前提下，信任关系反而更容易建立。跟谁建立不起来呢？就是那些 AI 还没用好的那些人。

**Weiyang**: 你说的很对。去年不是有人抱怨过 AIP 不好用吗？就是那个类似于超级表格或以前的 ADB 的东西。我做 B 端商务，有 3000 个客户，我也不知道该怎么对接。但我可以通过分析，知道这个公司里关键决策者的 MBTI 是什么类型。然后，我用这套工具，为每个公司的五个关键岗位，生成一套独一无二的、他们最喜欢听的推销 PPT。`3000 * 5 = 15000` 份 PPT，一晚上就能画完。这就是在照顾人的多样性。

**Weiqi (AR+AI软硬件)**: 你可以顺着人性去做。这聊多了，就是看你的 `believer` 是什么了。

**Weiyang**: 我跟你讲，自觉的这套 `soc` 算法，绝对是压抑人性的，它绝对是压抑多样性的。什么是鼓励多样性？Kimi K 二的写作就是鼓励多样性。什么是压抑多样性？换个前端就是紫蓝配色，这就是压抑多样性。

**Weiqi (AR+AI软硬件)**: 这就要看他的站位和生态位了。有些选择是逼不得已的。比如罗永浩，他再也回不去（只）做 AR 或 OS 了。他的 `journey` 和整个人生旅程就是这样，你不得不接受。这也是多样性的一部分，就是它最后不能变成他本来想变成的样子。

**Weiyang**: 没事儿，聊得有点远了。

**Weiqi (AR+AI软硬件)**: 我觉得最先被干掉的就是 `boss`。我经常开玩笑说，我要做一个 AI CU (Chief User)。

**Weiyang**: 那 `boss` 也不好说。CEO 是负责执行的，那你是负责愿景的吗？

**来新璐**: 我是一号员工。

**Weiyang**: 你是零号员工，那你肯定要负责 `final belief`。你就想，为什么张一鸣做的东西，以及他后来的人还不如他做的东西，我就不爱用。人的 `final believe` 不行。你到现在为止，抖音的商业化做得很好，可是它的搜推是以剥削用户的时间和所有人为基础的。那你说这个公司存在，给社会带来多大的正面价值？

**Weiqi (AR+AI软硬件)**: 它和拼多多不一样，有些地方它没法下沉，因为它本身又依赖于用户，但又想凌驾于用户之上。它本身是流量公司，本质上一切都是为了流量本身存在的。

**Weiyang**: 我在小红书写的东西，都是给我自己看的，也就一百多个粉丝。但我至少获得了五六十个陌生人朋友，甚至有人看着我这些抽象的玩意儿，来加我微信。这在抖音是不可能的，你有 500 粉丝都没人搭理你。

你的产品做到什么程度，用户数量级达到多少，才能让你真正去考虑你的搜推怎么做？在这些 `weber`（小众平台）上根本碰不到那个点。真到了那一天，你要选择张一鸣的路线，还是小红书的路线？到时候，你的工具、你输出的约束条件、大模型给你画的前端，其实都差不多。唯一的差别，就在于 `final belief`——你相信什么是对的。

## 结语

这场从 MBTI 到 Claude Code，从语音交互到工具哲学的漫谈，如同一幅生动的画卷，展现了 AI 时代开发者与工具之间正在重塑的、充满活力与思辨的新关系。我们看到的不仅是工具的进化，更是协作范式、价值观念乃至人性本身的延伸与反思。

当 AI 不再仅仅是执行命令的“奴仆”，而是拥有“性格”、能够“共情”的伙伴时，我们作为创造者，又该如何自处？或许正如 Weiyang 所言，最终的选择，不在于技术，而在于我们每个人内心的 **`final belief`**。

这不仅是一场关于代码的讨论，更是一场关于未来的探寻。而 Vibe Genius 社区，将持续见证并参与这场激动人心的变革。