

> **AI的未来，属于“智能体”（Agent）。** 当行业焦点从单一的巨型模型转向能够自主规划、执行、反思的智能体系统时，我们亟需一套经过实战检验的构建方法论。
> 
> 本文深入剖析了Anthropic的内部研究与实践，结合顶级AI团队的数百次对话精华，为您揭示构建高效、可靠、可信赖AI智能体的三大基石、两大架构范式、四大接口设计原则以及五种进阶架构模式。这不仅是一份技术指南，更是一张通往未来智能体时代的战略地图。

- 原文：https://artificialintelligencemadesimple.substack.com/p/how-to-build-agentic-aiagents，by [Devansh | Substack](https://substack.com/@chocolatemilkcultleader)
- 编译：手工川

### 核心洞见

- **大道至简**：成功的LLM系统始于简单的提示工程，只有在简单方案无法满足需求时，才应引入多步智能体系统。过度设计的复杂性是项目失败的催化剂。
- **架构分野**：Agentic AI系统主要分为两大流派：“工作流驱动”提供稳定性和可预测性，适合垂直领域的精确任务；“智能体驱动”则赋予模型更大的自主性，擅长应对开放和多变的需求，更适合水平领域的探索。
- **接口为王**：智能体与计算机的交互接口（ACI）是决定系统成败的“隐形英雄”。一个设计精良的ACI，通过清晰的工具、高效的反馈和坚固的护栏，能将智能体的潜力发挥到极致。
- **透明是金**：用户信任是AI应用成功的基石。透明化智能体的规划与推理过程，不仅便于调试和迭代，更是建立用户信任、推动产品采纳的关键。RAG系统的兴起，本质上是市场对透明化与可追溯性的胜利。

![Let me know how you think we should address the possible inequality gap.](https://poketto.oss-cn-hangzhou.aliyuncs.com/e1bb4740126ffc38eb7186aa75c4c362.png?x-oss-process=image/quality,q_90/rotate,0)


## 从单一模型到智能体系统

在人工智能的浪潮之巅，我们正见证着一场深刻的范式转移：从依赖单一、庞大的语言模型（LLM）一次性处理复杂查询，转向构建更为精密的**智能体系统（Agentic AI Systems）**。这场变革的核心思想，是将宏大的用户指令分解为一系列可管理、可审计的子任务，并由不同的专业组件协同完成。

智能体系统的本质，是一种**结构化的任务分解与执行框架**。它不再将LLM视为一个无所不能的“黑箱”，而是将其作为一个核心的“大脑”或“调度中心”，赋予其调用外部工具、访问知识库、以及跨交互周期维持记忆的能力。

[根据Anthropic的深入研究](https://www.anthropic.com/research/building-effective-agents)，这种架构带来了无与伦比的优势：
*   **更高的准确性**：通过将复杂问题分解，每个组件只需专注于解决其擅长的一小部分，大大降低了单点故障的风险。
*   **更强的可控性**：每一步操作都清晰可见，使得开发者能够轻松地进行调试、修正和优化，避免了“不可控的幻觉”。
*   **无限的可扩展性**：新的功能、工具或知识库可以作为独立的模块轻松接入，系统的能力得以持续、稳健地增长。

然而，构建一个高效的智能体系统并非易事。它要求我们超越单纯的模型调优，从系统工程的视角出发，遵循一套更为严谨的设计原则。接下来，我们将深入探讨支撑这一切的三大基石。

## 构建高效AI智能体的三大基石

Anthropic通过其内部研究和外部合作，提炼出了构建智能体系统的三个核心原则。这三大原则如同一座灯塔，指引着开发者在充满挑战的AI工程领域中航行。

### 原则一：大道至简——“恰到好处”的力量

在机器学习工程领域，一个普遍的陷阱是陷入对复杂性的盲目崇拜。面对“智能体”这一前沿概念，许多团队急于尝试最先进的多智能体协作框架，结果往往是创造出一个难以调试、成本高昂且性能不彰的“缝合怪”。

[正如一项关于软件工程的研究指出的](https://codinginterviewsmadesimple.substack.com/p/how-bad-is-architectural-complexity?utm_source=publication-search)，**“架构复杂性的差异可能导致生产力下降50%，缺陷密度增加三倍，以及员工流失率呈数量级增长。”**

因此，构建智能体系统的第一原则是**保持设计的极简主义**。与其一步到位追求终极形态，不如从一个“最小可行智能体”（Minimum Viable Agent）开始。这个基础模型仅需在基础LLM之上，增强三个核心能力：

*   **检索（Retrieval）**：赋予模型访问外部知识库（如数据库、文档）的能力，以获取实时、准确的信息。
*   **工具（Tools）**：让模型能够与外部服务（如API、计算器、代码执行器）交互，处理那些它本身不擅长的确定性任务（如数学计算、数据格式化）。
*   **记忆（Memory）**：使模型能够在多次交互中保留和利用关键信息，理解对话的上下文。

这种“恰到好处”的策略，能带来显著的工程优势：加快迭代速度、降低运营成本、简化调试流程，并因更少的错误而逐步建立起用户的信任。一个绝佳的例证是[Devin与Cursor的对比](https://youtu.be/oU3H581uCsA?si=YGFDrAThDYvC765N)。尽管Devin基于一个更强大的多智能体架构，旨在实现更广泛的功能，但许多开发者仍然偏爱架构更简洁的Cursor。原因是Cursor在核心功能上错误更少、速度更快、用户体验更流畅。

![Devin vs Cursor的比较说明了简洁架构在用户体验上的优势](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff28c32c2-1176-4313-b4ef-94d5aef64551_1000x416.png)

### 原则二：洞若观火——AI决策的透明化之道

信任是所有AI应用得以成功的心理基石。如果一个系统给出的决策缺乏解释，用户将永远对其持怀疑态度，这将严重阻碍产品的采纳和后续的迭代改进。因此，**透明性**是高效智能体系统不可或缺的组成部分。

一个透明的系统具备以下关键价值：

*   **可调试性**：当出现问题时，透明的系统能让开发者迅速定位故障点并进行修复，这对于“黑箱”系统而言是一种奢望。
*   **用户信任**：公开展示智能体的思考链（Chain-of-Thought）或规划步骤，能够有效降低用户的疑虑，鼓励他们更深入地使用产品。
*   **伦理考量**：透明的智能体更容易接受审查和监督，确保其行为符合伦理规范和社会期望。

近年来，检索增强生成（RAG）技术之所以能超越微调（Fine-Tuning）和复杂的提示工程，成为企业级应用的首选，其背后一个被低估的原因正是**透明性**。RAG系统能够明确指出其回答的信息来源，为用户提供了一条可验证的路径。

![根据Menlo VC的报告，RAG已成为企业生成式AI应用中最主流的技术](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c2e77bf-a339-4078-8b88-0679842109a6_1000x411.png)

以法律AI公司IQIDIS为例，其产品的一个核心卖点就是文档引用功能。该功能允许律师用户轻松验证AI生成的任何法律论点或声明的来源文件，极大地提升了产品的可信度。更进一步，IQIDIS甚至向部分用户开放了底层的嵌入和知识图谱，让他们能够直观地看到AI是如何理解案件文档中各个实体之间关系的，并允许用户手动编辑这些关系，使AI能够根据律师独特的专业知识进行定制化调整。

![IQIDIS通过可视化知识图谱让用户理解并编辑AI的“思维过程”](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd2bcad5b-fe50-4521-954d-4aa3a09173db_976x716.jpeg)
 
这种 **“过程可验证、结果可编辑”** 的透明化设计，成功解决了生成式AI在严肃场景中最大的痛点：用户因验证和调试输出而耗费大量时间，从而抵消了生产力收益。

### 原则三：人机共舞——智能体-计算机接口（ACI）的设计哲学

正如人机交互界面（HCI）是传统软件的灵魂，**智能体-计算机接口（Agent-Computer Interface, ACI）** 则是决定智能体系统成败的“隐形英雄”。ACI指的是智能体与其可调用的工具、API和环境进行交互的系统设计。一个强大的智能体不仅需要“会思考”，更需要“会使用工具”，而ACI正是连接思考与行动的桥梁。

精心设计的ACI应遵循以下原则：

*   **工具是核心，而非附加品**：必须将工具的设计与集成置于系统架构的核心位置。
*   **定义明确的工具规范**：每个工具的文档都应尽可能详尽，清晰地说明其输入/输出格式、边界条件、错误处理和使用示例。这能引导LLM更准确地选择和使用工具。
*   **迭代测试与“防错防呆”**：必须反复测试工具的使用场景，确保其在应工作时正常工作，在不应工作时不被误用。可以借鉴制造业的“Poka-Yoke”（防错法）思想，通过增加约束来防止智能体轻易地误用工具。

[在解决复杂软件工程任务的SWE-bench基准测试中，表现优异的AI智能体无一不依赖于一个设计精良的ACI](https://artificialintelligencemadesimple.substack.com/p/aci-has-been-achieved-internally?utm_source=publication-search)。我们将在后续章节中，通过SWE-Agent的案例来深入剖析ACI的设计实践。

## 架构分野：工作流驱动 vs. 智能体驱动

在智能体系统的设计哲学中，存在着两种主流的架构范式：**工作流驱动（Workflow-based）** 和**智能体驱动（Agent-based）**。理解它们的区别，对于选择正确的技术路径至关重要。

*   **工作流驱动系统**：在这类系统中，LLM、工具和其他组件的调用顺序和逻辑由**预定义的代码路径**严格编排。LLM在其中扮演的是一个强大的“组件”，在固定的流程节点上发挥作用。
*   **智能体驱动系统**（为避免混淆，下文称之为**A2系统**）：在这类系统中，LLM拥有更高的自主性，它能够**动态地决定**自身的思考过程和工具使用顺序，以达成最终目标。

我们可以用一个生动的比喻来理解这两种范式：
*   **工作流驱动**好比一支战术纪律严明的球队（如瓜迪奥拉的巴塞罗那），每个球员（组件）的角色和跑位（流程）都经过精心设计和反复演练。这带来了极高的执行效率和稳定性，尤其擅长处理定义明确的、可重复的任务。但其缺点是灵活性不足，一旦遇到流程之外的意外情况，或者某个关键组件失灵，整个系统可能会陷入僵化。
*   **A2系统**则像一支巨星云集的球队（如安切洛蒂的皇家马德里），教练只设定一个大的战术目标，然后给予球员们极大的场上自由度，让他们依靠天赋和默契即兴发挥。这种系统非常灵活，能够应对各种复杂的、非结构化的挑战，并时常能创造出超越预期的结果。但其代价是稳定性较差，容易出现“莫名其妙”的崩溃，且事后诊断和修复问题也更为困难。

![手工川制图：工作流 VS 智能体](https://poketto.oss-cn-hangzhou.aliyuncs.com/272567edaa27a9fe20fbffd2bac79708.png?x-oss-process=image/quality,q_90/rotate,0)


这两种架构的选择，直接关系到产品的市场定位：

*   **工作流驱动系统**更适合**垂直领域的解决方案**。因为在特定行业（如法律、金融、医疗），许多任务流程是标准化的。通过构建高度优化的工作流，企业可以向用户提供性能稳定、成本可控且结果精确的服务。
*   **A2系统**更适合**水平领域的通用平台**。其固有的灵活性使其能够服务于更广泛的用户和更多样化的场景。这也是为什么大多数前沿AI研究（通常由技术人员而非领域专家主导）都偏向于A2系统，因为它们追求的是通用能力的突破。

一个值得深思的现象是，尽管法律科技领域吸引了数十亿美元的投资，但至今仍未出现颠覆性的AI产品。许多初创公司盲目地复制前沿AI实验室的A2范式，试图构建一个“无所不能”的通用法律AI，结果却是产品表现平平，且云计算成本高昂。他们忽视了法律服务本质上是由一系列高度专业化、流程化的工作流组成的，这恰恰是工作流驱动系统的用武之地。

## 深度剖析：卓越ACI的四大设计原则与SWE-Agent实践

智能体-计算机接口（ACI）是连接智能体“大脑”与外部“手脚”的神经系统。一个卓越的ACI设计，能让智能体的行动变得精准、高效且可靠。

### 卓越ACI的四大设计原则

1.  **动作的简洁与清晰**：ACI提供的命令应该是直观且易于理解的。避免用复杂的文档和海量的选项来压垮智能体。简洁的命令可以最大程度地减少对复杂示例或微调的依赖。
2.  **操作的高效性**：将常见的复合操作（如文件导航和编辑）整合成尽可能少的动作。高效的动作能让智能体在一步之内取得实质性进展。要警惕那种需要智能体通过多个简单动作的组合才能完成一个高阶操作的设计，因为它会严重拖慢执行效率。
3.  **信息丰富的环境反馈**：高质量的反馈至关重要。当智能体执行一个动作后，ACI应提供关于环境当前状态和该动作所产生影响的、相关且简洁的信息。例如，编辑文件后，立即返回更新后的文件内容片段，而不是让智能体再次查询。
4.  **防止错误传播的护栏**：语言模型和人一样会犯错，但它们从错误中恢复的能力通常较差，很容易陷入无效的循环。ACI中应内置“护栏”，例如一个自动检测语法错误的代码检查器，它可以帮助智能体及时发现并纠正问题，防止小错误演变成大灾难。

### 案例研究：SWE-Agent如何利用ACI解决复杂软件工程任务

SWE-Agent是一个旨在让语言模型扮演软件工程师角色的系统，它通过一个构建在Linux Shell之上的、设计精良的ACI，使其能够高效地搜索、导航、编辑和执行代码。

#### 搜索与导航

在纯Shell环境中，LLM常常需要通过一连串`cd`、`ls`、`cat`命令来探索代码库，效率低下。即使使用`grep`等搜索命令，也常常被海量的无关结果所淹没。

SWE-Agent的ACI引入了特制的命令，如`find file`、`search file`和`search dir`。这些命令返回的是搜索结果的简洁摘要，并**将结果数量限制在50个以内**。如果结果过多，系统会提示智能体优化其搜索查询。这一设计至关重要，因为它避免了LLM的上下文窗口被无用信息污染，帮助其快速定位关键代码。这一点与[Diff Transformer的研究发现不谋而合](https://arxiv.org/abs/2410.05258)，该研究指出Transformer模型常常会过度关注不相关的上下文信息（即注意力噪声）。

![SWE-Agent的ACI命令简化了代码库的搜索和导航](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa2a33bf4-9e9d-44c4-a01b-95975dbd744e_1000x199.png)

#### 文件查看器

定位到文件后，智能体可以通过`open`命令调用一个交互式文件查看器。该查看器每次最多显示100行代码，并提供`scroll down/up`和`goto`命令进行导航。它清晰地显示了当前窗口在整个文件中的位置，帮助智能体在不撑爆上下文的前提下，精准地理解文件内容。

#### 文件编辑器

SWE-Agent的`edit`命令与文件查看器协同工作，允许智能体通过一个命令替换文件中的指定行范围（`edit <start_line> <end_line> <replacement_text>`）。编辑完成后，ACI会**立即在文件查看器中显示更新后的内容**，提供即时反馈。此外，编辑器还集成了代码检查器（linter），如果编辑引入了语法错误，该操作将被撤销，并提示模型重试。这种带护栏的、反馈及时的编辑机制，相比于传统Shell中的`sed`或重定向等易错操作，极大地提升了编辑的成功率和效率。

#### 上下文管理

SWE-Agent的ACI通过信息丰富的提示、错误消息和历史记录处理器，来维持智能体上下文的简洁和高效。例如，它会自动折叠超过五轮之前的交互观察，只保留关键的动作历史，从而为新的交互腾出宝贵的上下文空间。

## 进阶之路：构建更强大AI智能体的五种架构模式

当掌握了基础的构建块（LLM、工具、检索、记忆）之后，我们可以通过组合这些组件，探索更复杂的架构模式来应对更艰巨的挑战。

### 模式一：提示链（Prompt Chaining）

这是一种将复杂任务分解为一系列线性、顺序的提示调用的模式。每个步骤的输出成为下一步的输入，如同流水线作业。

*   **适用场景**：任务可以被清晰地分解为固定的、前后依赖的子任务。
*   **示例**：
    1.  第一步：生成一篇营销文案的草稿。
    2.  第二步：将草稿翻译成另一种语言。
    3.  第三步：根据目标语言的文化习惯，对翻译后的文案进行润色。

### 模式二：路由（Routing）

路由模式通过一个初始的分类或决策步骤，将输入引导至最适合处理它的下游任务（可以是不同的提示链、工具或其他组件）。

![手工川制图：路由模式](https://poketto.oss-cn-hangzhou.aliyuncs.com/6b37d736e7b2c62f5978c3c762eda42f.png?x-oss-process=image/quality,q_90/rotate,0)


*   **适用场景**：需要根据输入的类型或意图，采用截然不同的处理逻辑。这有助于避免构建一个试图“一招鲜吃遍天”的臃肿提示，从而提升在各类输入上的性能。
*   **示例**：一个客服机器人首先判断用户意图是“查询订单”、“技术支持”还是“投诉建议”，然后将请求分发给专门处理该类问题的子系统。

### 模式三：并行化（Parallelization）

该模式通过同时执行多个LLM调用来处理任务，然后将它们的输出进行聚合。它主要有两种变体：

*   **分块（Sectioning）**：将一个大任务分解为多个可以独立并行处理的子任务。
*   **投票（Voting）**：让多个LLM实例或使用不同提示的LLM，独立完成同一个任务，然后通过某种机制（如多数投票）来决定最终结果。

*   **适用场景**：
    *   **分块**：任务可被分解为互不依赖的部分，以提高处理速度（例如，总结一本书的不同章节）。
    *   **投票**：需要对结果进行交叉验证，以提高准确性或鲁棒性（例如，进行内容审核，多个模型投票决定内容是否违规）。

### 模式四：编排器-工作者模式（Orchestrator-Workers）

这是更高级的智能体协作模式。一个中心的“编排器”LLM负责将主任务分解，并将子任务动态地分配给多个专用的“工作者”LLM（或工具）。最后，编排器负责汇总和综合工作者的产出，形成最终的解决方案。

![手工川制图：Orchestrator-Workers](https://poketto.oss-cn-hangzhou.aliyuncs.com/206695b9d0104d047e91167e4bda1f41.png?x-oss-process=image/quality,q_90/rotate,0)


*   **适用场景**：处理极其复杂的、需要多种不同技能和视角的综合性任务。经典的RAG系统，尤其是那些包含意图识别、多路检索和个性化生成模块的复杂RAG，就是这种模式的体现。
*   **示例**：在IQIDIS的系统中，一个“用户画像”智能体负责理解律师的特定需求，一个“上下文感知检索”智能体负责高效查找相关法律文件，最后由一个“论证生成”智能体将所有信息整合成一份个性化的法律备忘录。

### 模式五：评估器-优化器循环（Evaluator-Optimizer）

在这种模式中，一个LLM（优化器）负责生成初始响应，而另一个LLM（评估器）则根据一系列明确的标准对其进行评估和批判，并提供反馈。优化器再根据这些反馈进行迭代修改，形成一个自我完善的闭环。

*   **适用场景**：任务有明确的、可量化的评估标准，且迭代改进能够带来显著价值。
*   **示例**：
    *   **文学翻译**：一个“翻译”LLM给出初版译文，一个“评论”LLM从“信、达、雅”等多个维度提出批评意见，然后“翻译”LLM据此进行润色。
    *   **代码优化**：一个LLM生成代码，另一个LLM评估其性能、可读性和安全性，并提出改进建议。

## 结语：回归第一性原理，构建可信赖的智能体

从Anthropic的实践到业界的广泛探索，一条清晰的路径已经浮现：构建卓越的AI智能体系统，并非一场关于模型参数和复杂框架的“军备竞赛”，而是一次回归软件工程**第一性原理**的旅程。

**大道至简**，要求我们抵制不必要的复杂性，从最小可行的产品出发，稳步迭代。**架构选择**，提醒我们必须根据具体的业务场景，在“工作流的精确”与“智能体的灵活”之间做出明智的权衡。**接口设计**，揭示了智能体与外部世界交互的通道是其能力放大的关键。而**全程透明**，则是我们在这个充满不确定性的时代，赢得用户信任的唯一途径。

未来，真正能够改变世界的AI应用，将是那些不仅强大，而且可靠、可维护、并最终被其用户深度信赖的智能体系统。这条路充满挑战，但遵循这些从实践中提炼出的原则，我们将能更稳健地迈向那个由智能体赋能的未来。****