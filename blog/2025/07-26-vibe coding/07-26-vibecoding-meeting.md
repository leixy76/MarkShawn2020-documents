

## **第一部分：开场与Cloud Code Agent介绍**


**南川 Mark @手工川:** 大家好，我们今天的分享会正式开始。本期我们邀请到了一位在cloud agent开发方面有丰富经验的朋友Kai。

首先，我给大家简单介绍一下我们自己研发的工具CCM。通过npm install安装后，你就可以使用ccm指令。它有很多子命令，比如统计项目cloud使用情况、聊天记录瘦身、费用统计等。我们今天要重点讲的是monitor功能。启动ccm monitor后，它会打开一个界面，实时监控所有正在运行的cloud程序。

举个例子，当你在一个新项目中调用cloud进行初始化并生成cloud.md文档时，界面上会显示出相应的任务（to-do）。这里的每一个任务（task）实际上都会启动一个所谓的agent。我们通过ccm monitor就可以把每个task的执行情况监控起来。

在cloud code中，你可以通过agent list命令查看所有内置的agent。当然，你也可以创建新的agent。我自己目前用得比较多的是自定义的commands，agent是其中的一种高级形式。未来cloud code会提供越来越丰富的特性，如agents、commands、tools等，学习和掌握这些工具的门槛会越来越高，建议大家尽早开始学习。

我整理了一些有用的学习资源，之后会放在我们Vibe Coding社区的专栏里。其中一个很棒的资源是awesome-cloud-code这个GitHub仓库，它汇总了cloud code相关的各种工具和子项目，比如hooks和tools，相信以后也会加入agent相关的内容。

另一个推荐的资源是cloud code官方文档的镜像仓库。你可以把它拉到本地，然后交给AI进行分析，这对于深入理解cloud code非常有帮助。

目前，关于cloud code agent的深入研究还处于早期阶段。但agent这个范式本身已成为一个显学。如果我们能深入研究它，无论是对于开发AI产品，还是提升个人开发效率，都将有巨大的帮助，甚至可能彻底改变我们的开发方式。例如，有一个叫sweep.dev的框架，它定义了许多agent，涵盖了架构师、前端、后端、分析师等多种角色。我们可以思考，是否能将这些外部的agent内化成cloud code内部自己的agent。

**Kai:** Hello，大家好。我之前做了多年全栈开发，从2022年ChatGPT元年开始接触AI。我的感受是，从去年开始，AI赛道真正火了起来。

我主要关注的是AI在应用开发层面的落地。最近cloud code agent发布后，我非常感兴趣，因为它和我最近在做的一个小项目息息相关。我一直在思考如何用AI的方式让项目开发效率更高。

最近比较火的一个概念叫“规范驱动开发”（Specification-Driven Development, SDD），它解决了一个核心问题：普通人提出的需求往往是模糊的，导致AI生成的代码不符合预期。SDD的范式是，我们先提出初步需求，AI会帮助我们生成更规范的文档，如需求（Requirements）、设计（Design）和任务列表（Task List）。基于这些精确的文档，AI生成的代码质量会高得多。

这张流程图就是我用cloud code生成的。大语言模型在画图（如Mermaid、Excalidraw）方面能力很强，大家可以多试试。

我用这个模式做了个实验，项目是一个YouTube学习助手。用户提交一个YouTube链接，工具会根据视频字幕等信息生成一个to-do list，帮助用户跟着视频一步步操作，提高学习效率。这个需求我非常熟悉，我只用了一句很简单的描述作为起点，让AI帮我生成to-do list。整个过程只花了大约半小时，AI就帮我完成了技术架构分析、代码结构设计和数据库设计。

**南川 Mark @手工川:** Kai，问一下，你演示界面顶部的“Requirements”, “Design”, “Task List”这几栏是它内置的吗？

**Kai:** 这是固定的，它背后是prompt写死的。我其实是把最近很火的Kilo.dev这个工具的工作流（workflow）给“扒”了下来。Kilo的核心优势在于它优秀的prompt设计，非常细致。我做的就是把它的prompt核心思想，迁移到了cloud code的agent里。

Kilo的这套工作流（需求 -> 设计 -> 任务）能确保整个开发过程在可控范围内进行。昨天最让我惊喜的是，按照这个流程，我只用几句话描述了需求和设计要点（比如用哪个数据库版本、什么框架等），AI就帮我生成了非常靠谱的task list。

拿到task list后，我会进入plan模式，让AI对计划进行二次审核。最终生成的代码结构非常好，甚至比我之前自己写的还要好。我当时分别用千问和cloud code的模型做了测试，发现在这个优秀的框架下，即便模型能力稍有差异，产出代码的质量和可控性都非常高。

**CharlieYu:** 我有个思考，现在的AI Agent时代似乎还没有一个统一的开发框架，或者说“元框架”。Kilo提供了一种框架，cloud.md也是一种。大家有没有看到更多关于这方面的讨论？

**Kai:** 这方面的探索其实很多，比如sweep.dev，还有个叫aicommit的，都在做类似的事情，就是把传统的软件工程经验和AI结合起来，防止AI“乱跑”。但要形成统一标准很难，因为每个项目、每个人的背景和经验都不同。长期来看，我们可能真的不再需要IDE，直接通过自然语言来编程。

**CharlieYu:** 我在实际使用中发现，AI有时会做得“太多”。比如我只想让他管理模型的几个选项，他却会帮我设计一整套用户权限系统。

**Kai:** 没错，所以我会在我的code.md里明确写下指令：“Don't write code unrelated to the current task.”（不要写和当前任务无关的代码）。即便如此，有时还是会发生。所以我的开发流程是：每当AI完成一步，我立刻检查（review）它做了什么，然后马上提交（commit）。一定要小步快跑，否则你让它开发一个功能，它可能给你做了三个，项目就失控了。

## **第二部分：深入探讨Agent、上下文与编程范式**

**刘雷:** 我想问个问题，这几个sub-agent之间，是有一个主线程（main thread）去调用它们吗？它们之间会自动通信和协作吗？

**Kai:** 它有一个主线程负责delegate（委派）任务。你可以把agent想象成你的团队成员，你作为老板，把任务分发给他们。它支持并行操作，你可以同时跑多个任务。调用方式也很自然，你直接用自然语言描述就行，它会自动识别并调用合适的agent，不一定需要用斜杠命令（slash command）。

**流年:** Kai你这套agent的提示词是自己写的还是内置的？它和Cursor有什么区别？

**Kai:** 提示词是我自己写的，主要是借鉴了Kilo的prompt。这些工具本质上都是调用大模型API，所以它们的prompt是可以被“hack”并化为己用的。我认为，随着cloud code的sub-agent功能越来越强大，很多外部工具的核心逻辑都可以被吸收进来。

**流年:** 我主要还是用Cursor做半自动化的提效工作。对于公司级的复杂项目，感觉还不能完全依赖AI来写代码，它目前更适合写一些玩具项目或简单的产品。

**YiAn:** Kai你好，我想继续问一下agent的问题。你这套工作流和sweep.dev的思路很像，但sweep需要人一步步手动执行。你这个agent是能实现全自动，从需求到实践一步到位吗？

**Kai:** 理论上可以。你可以写一个prompt，让他“先写需求，再做设计，然后规划，最后自动执行所有任务”。但实际操作中，我不会这么做。我是软件工程师，我需要掌控全局。我会分步进行，比如先用“需求agent”写需求文档，写完后我立刻修改确认，确保错误不会被累积。目前所有工具都受限于context window（上下文窗口）的大小，现在的工具还无法做到在长流程中智能地清理和管理上下文，所以完全的自动化在工程上还很难实现。

**YiAn:** 那你觉得agent模式对比传统的slash command，优势在哪里？

**Kai:** 很简单，slash command会占据主对话的上下文空间。你执行的命令越多，上下文就越“污染”。而sub-agent在独立的上下文中运行，主对话的“脑容量”（working memory）能保持清爽，这让后续的交互性能更好。

**南川 Mark @手工川:** 我总结一下，cloud code生态里不同工具有不同定位。slash command在主进程中运行，会消耗上下文。而agent模式则在独立的后台进程（可以理解为sidecar）中运行，非常适合执行那些可以并行或无需等待结果的“伺服任务”。

**大树临风:** 我有个问题，sub-agent的不可替代性在哪里？我感觉它解决的上下文隔离问题，我多开几个终端也能做到。我找不到一个非用sub-agent不可的场景。

**南川 Mark @手工川:** 这个问题很好。我来回答一下。首先，sub-agent的概念在cloud code里一直存在，最近的更新只是开放了让用户自定义agent的能力。它的不可替代性在于**任务之间的通信和结果返回**。

当你的主任务需要等待一个子任务的结果时，你就必须使用sub-agent。子任务完成后，它的结果会返回给主进程，主进程再继续执行。如果你是多开终端（也就是多个session），session之间是完全隔离的，目前cloud code不支持session间的通信。所以，如果你的需求依赖于子任务的返回结果，那就必须用sub-agent。

**jojo:** 这是否意味着cloud code做了一套agent之间的通信协议，类似Google的Agent-to-Agent（A2A）协议？

**南川 Mark @手工川:** 我觉得有点像。

**大树临风:** 那么，对于开发效率本身，比如我开一个“前端agent”，它写前端代码的能力会比我重开一个终端更强吗？

**阳光彩虹小白马:** 从最终编码结果来看，可能没有区别。但它的价值可能体现在编码前的阶段，比如需求梳理和规划。

**Lei Liu:** 我认为agent有两个潜力。第一，它可以被保存在项目或用户级别，这意味着你可以持续“培养”一个agent，比如做一个越来越聪明的code review agent，成为可复用的资产。第二，在自动化方面，未来可能会实现agent之间的自主协作。比如，“写代码agent”写完后自动交给“review agent”，发现问题再反馈回来修改，形成一个闭环，这才是它真正的意义所在。

**Weiyang:** 我个人认为，agent的核心价值在于解决上下文管理问题。现在所有基于Transformer的模型，当输入上下文超过一个临界值（比如64K tokens），其召回能力（recall）就会出现断崖式下跌。

所以，agent的一个重要作用就是做任务拆分，确保每个任务都在一个高效的、精简的上下文窗口内完成。当你处理一个超过5万行代码的复杂项目时，用不用agent的差别会非常明显。在小项目里，你可能感觉不到区别。

**南川 Mark @手工川:** 我对此深有体会。最近我发现，当项目上下文变得非常长时，即使我在全局的cloud.md里定义了“不能硬编码”的规则，AI有时还是会违反它。它不是忘记了，而是在庞大的上下文中，这条规则的“权重”被稀释了。所以，未来的Vibe Coding，核心就是**上下文工程**。谁能提供最精确、最简洁的上下文，谁就能得到最高质量的回复。

**Lei Liu:** 我们在使用cloud code时，怎么去控制上下文的大小呢？

**南川 Mark @手工川:** cloud code有自动的compact（压缩）机制，当上下文接近上限时会触发。但更推荐的最佳实践是，在一个干净的任务节点完成后，手动执行一次compact命令，能将上下文大小压缩到10%以内。对于一些必然会超出上下文窗口的复杂任务，比如分析一个几百K的HTML文件或者一张4K截图，你需要先用其他工具进行预处理（比如总结、压缩），再把结果喂给cloud code。

**阳光彩虹小白马:** 我也分享个技巧。我不懂前端，当需要写网页时，我会先用大白话向ChatGPT描述我的需求，然后让它帮我翻译成一句专业的、给cloud code的prompt。这样prompt更精简，效果也更专业。

**南川 Mark @手工川:** 我总结一下今天的核心观点：未来Vibe Coding的核心是**上下文工程**。这包括：

1. **输入前的预处理**：对大数据（如图片、长文档）进行压缩和特征提取。
    
2. **精确的上下文提供**：避免提供模糊或过多的信息，确保上下文的信噪比。
    
3. **多层级的记忆管理**：像操作系统一样，有内存、硬盘、外接磁盘。cloud code的@文件引用机制就类似这种分层存储，理论上可以让上下文无限扩展。
    
4. **智能的任务拆分**：利用agent将大任务拆解成多个在最佳上下文窗口内执行的小任务。
    

## **第三部分：L3 vs L4，编程的未来与实战演示**

**大树临风:** 我提一个比较悲观的观点。我认为Vibe Coding会长期停留在L3自动驾驶阶段。核心问题是：**你到底要不要review AI生成的代码？** 如果你要review，那么瓶颈就是你自己的速度。

我用cloud code写了一个多月的C++通信代码，这类代码耦合性极强。开发一个新功能，AI必须理解几乎所有的历史代码和框架，这导致上下文非常长，效果大打折扣。如果模型层面没有突破，我觉得在工程上再怎么优化，也只是L3。

**洪楷@探索已知:** 这个问题本质上取决于你代码本身的解耦程度。如果代码本身就是高度模块化的，这个问题就相对较小。我们用cloud code对大型C++项目做调整时，会先明确要改动的大致模块，而不是把整个项目丢给它。AI实际上也只会重点分析相关的代码单元，而不是把所有文件都加载到上下文中。

**大树临风:** 我理想的效果是，在完备的文档和测试驱动下，我让AI尽量自己写，我不想review。当测试能覆盖所有corner case，那么通过测试的代码就是好代码。我畅想一种“老虎机”模式：开100个cloud code实例，让它们24小时不停地尝试，直到有一个通过了所有测试。但目前来看，token有限，效率太低，还不如L3。

**CharlieYu:** 我觉得问题是永远在的，抽象只是把问题隐藏了。总需要有人去解决底层的问题。就像CPU和GPU操作，总需要有人去写最底层的代码。

**Lei Liu:** 我来分享一个视角。我90年代就在写代码，那时最牛的程序员是写汇编的，他们瞧不上后面写高级语言的。但现在99%的程序员都不会碰汇编了。抽象层级在不断提升，每一代人都有自己时代的工具和平台，我们不用替后人担心。

**大树临风:** 是的，**一代人有一代人的抽象**。就像今天你开汽车，你不需要懂内燃机的五种点火方式。未来的编程也是一样，你只需要关注你要解决的问题本身，也就是“将电能转化为解决问题的思维”，而不需要学习各种API的搬运技巧和环境配置。

**Gpt:** 一代人有一代人的抽象，这话很贴切。要学习和投入精力的东西一样都不会少，只是换了内容和形式。

**阳光彩虹小白马:** 那如果大家都会Vibe Coding，传统的编程教学还有意义吗？还需要从hello world开始学吗？

**Lei Liu:** 学编程的意义不一定是为了去编程。学习过程本身能锻炼思维。就像你有了自动驾驶，但如果你自己开过车，对车的理解更深，遇到危险时活下来的机会可能就更大。

**大树临风:** 这个问题的答案很简单。商业的本质（如利润）是永恒的，但做生意的方式在变。你不再需要懂怎么跑工商局，开个网店就行。编程也一样，数据结构、算法思想这些本质可能需要学，但具体某个API怎么用，这些细节未来可能都不再重要。

**Kai:** 我来给大家演示一下AI做页面设计。很多人觉得AI做的页面有“AI味”，但其实是可以优化的。比如，这个页面就是典型的AI生成，布局和色彩都很模板化。

（Kai展示屏幕）

我并没有用很复杂的技术，只是利用我对CSS的理解，定义了一套主题（design token），包括色彩、布局、字体等。现在的shadcn/ui这类工具已经把主题系统格式化了，大模型对这种格式化的东西理解得非常好。我只是把我想要的主题token喂给它，你看，这是改版后的效果，是不是比之前好很多？

所以，AI的能力是被低估了的。只要你掌握了UI设计的基本原则（design token、layout等），你就能引导AI生成非常高质量的界面。而这些原则，你甚至可以直接问AI来学习。

**南川 Mark @手工川:** 我在Kai的基础上补充一点：要理解**编码（Encoder）和解码（Decoder）**的概念。Transformer之所以强大，就是因为它能把语言高效地压缩和解压。

在UI生成这个场景，用图片作为输入，效果其实不是最好的，因为图片对于模型来说是一种有损的、非结构化的信息。更好的方式是，**直接把目标网站的HTML喂给模型**。HTML本身是结构化的文本，包含了精确的样式和布局信息，模型能完美理解。

我就是用这种方法，把一个网站的HTML喂给cloud code，让它提取出设计风格，生成一份design token的JSON文件。之后，我所有的开发都基于这份“设计指南”，确保所有组件风格统一。这样做出来的产品，效果远比直接给一张截图要好。

核心思想是，**尽可能用结构化的、无损的文本格式作为AI的输入**。视频、图片、自然语言，你都要思考如何找到一种最高效的“编码”方式，把它们转换成模型最容易理解的形态。

另外，我还想分享一个独家技巧：**分层思考指令**。cloud code的plan模式虽然能让AI更深入思考，但不够灵活。所以我开发了一套slash command，比如/t（思考）、/tt（深度思考）、/ttt（极限思考）。这些命令背后是不同复杂度的prompt，可以针对不同任务，调用不同层级的思考深度。

（南川Mark演示了如何使用generate-command命令，在一分钟内创建了一个新的/meow-preface命令，让AI在每次回答前都说一句“喵喵喵”）

这个功能的核心是**元编程**，也就是用AI来创建和管理AI自己的行为（指令）。

最后，我想分享一个能极大提升效率的插件：code-inspect。它能让你在浏览器中点击任何一个DOM元素，IDE就会自动打开对应的源代码文件并定位到光标。这在Vibe Coding时代太有用了，你可以瞬间锁定要修改的组件，然后给AI一个极其精确的指令：“请修改这个文件里的这个组件”。这比你用“请修改页面顶部的导航栏”这种模糊描述，效率高十倍，结果也准确十倍。

**总结一下，Vibe Coding的高效秘诀就是：精确的上下文 + 恰当的思考深度 + 强大的自动化工具链。**

**南川 Mark @手工川:** 今天的分享非常热烈，内容也很丰富。如果大家觉得这种形式不错，我们可以每周都组织一次，共同跟进AI的迭代，一起成长。感谢大家的参与，我们下次再会！